{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18FuJKM81ZO1"
      },
      "source": [
        "# Session 9: Coding Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4j569hbz1tA"
      },
      "source": [
        "## Emotion classification problem for Shopee comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU7RPRtYDQVN"
      },
      "source": [
        "**Install `fasttext` for Pretrained Word Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Oh6qbJDVoS",
        "outputId": "27f78e2f-7e44-4e12-efe6-7cda31a13704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-1i0lsjtu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-1i0lsjtu\n",
            "  Resolved https://github.com/facebookresearch/fastText.git to commit 440f46ac8811db0ce7ecb7dfb04f694453187db3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4291600 sha256=5ce85a6bdf3dc2bae7e5b922e9d6e0e520bb2b04e31bf69edc6bb98f86b7f9dd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sgv5go5h/wheels/3d/b7/8f/678f8b04408b579e2acad5f2416797aee4ebfe3529049a03b2\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/fastText.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY3t2dXLt-jt",
        "outputId": "3d3637ca-0883-40f9-f146-e0d9be48a158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWMmH_Kh0HPH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h18yQzEu0CZn",
        "outputId": "88adb37c-9d99-441b-ab7b-24357d27dd70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-64a01368-b4f1-42ca-93d5-c6eb2b0919c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_000000</td>\n",
              "      <td>Dung dc sp tot cam on shop Đóng_gói sản_phẩm r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_000001</td>\n",
              "      <td>Chất_lượng sản_phẩm tuyệt_vời . _Son mịn nhưng...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_000002</td>\n",
              "      <td>Chất_lượng sản_phẩm tuyệt_vời nhưng k có hộp k...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_000003</td>\n",
              "      <td>: ( ( Mình hơi thất_vọng 1 chút vì mình đã kỳ_...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_000004</td>\n",
              "      <td>Lần trước mình mua áo_gió màu hồng rất ok mà đ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64a01368-b4f1-42ca-93d5-c6eb2b0919c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b3e3d6bc-7fcf-44a0-bcbf-307331d448fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3e3d6bc-7fcf-44a0-bcbf-307331d448fd')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b3e3d6bc-7fcf-44a0-bcbf-307331d448fd button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64a01368-b4f1-42ca-93d5-c6eb2b0919c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64a01368-b4f1-42ca-93d5-c6eb2b0919c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             id                                               text  label\n",
              "0  train_000000  Dung dc sp tot cam on shop Đóng_gói sản_phẩm r...      0\n",
              "1  train_000001  Chất_lượng sản_phẩm tuyệt_vời . _Son mịn nhưng...      0\n",
              "2  train_000002  Chất_lượng sản_phẩm tuyệt_vời nhưng k có hộp k...      0\n",
              "3  train_000003  : ( ( Mình hơi thất_vọng 1 chút vì mình đã kỳ_...      1\n",
              "4  train_000004  Lần trước mình mua áo_gió màu hồng rất ok mà đ...      1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML-intensive/data/sentiment_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2s9o5tR23Mg"
      },
      "source": [
        "Print a few compliments and a few critical comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6OCBS1Z0CYY",
        "outputId": "33f38801-59e6-4159-db99-833919abede4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critical- LABEL = 1\n",
            ": ( ( Mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng cuốn sách khá nhiều hi_vọng nó sẽ nói về việc học_tập của cách sinh_viên trường Harvard ra sao những nỗ_lực của họ như_thế_nào 4h sáng ? tại_sao họ lại phải thức dậy vào thời_khắc đấy ? sau đó là cả một câu_chuyện ra sao . Cái mình thực_sự cần ở đây là câu_chuyện ẩn dấu trong đó để tự bản_thân mỗi người cảm_nhận và đi_sâu vào lòng người hơn . Còn cuốn sách này chỉ đơn_thuần là cuốn sách dạy kĩ_năng mà hầu_như sách nào cũng đã có . BUồn ...\n",
            "Lần trước mình mua áo_gió màu hồng rất ok mà đợt này lại giao 2 cái áo_gió chất khác như vải mưa ý : ( (\n",
            "Các siêu phẩm thấy cấu_hình toàn tựa tựa nhau . Ko còn sự đột_phá lớn nữa . Chỉ là nâng_cấp . Khác nhau về kiểu_dáng . Htc này vs giá trên thật lòng khó cạnh_tranh mạnh vs siêu phẩm khác , chỉ dành cho fan của họ thôi .\n",
            "Đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái k chạy mua ve phải sửa\n",
            "Giao thiếu mình cái này rồi shop ơi T ^ T\n",
            "không hài_lòng sản_phẩm cho lắm . giặt lan đầu_tiên da nhoe màu hết rồi .\n",
            "Đồng_hồ thì đẹp thật . Nhưng tại_sao kim lúc chạy lúc đứng . Nhắn_tin thì ko trả_lời . Mấy bạn lưu_ý đừng mua nữa .\n",
            "\" Cũng hơi bất_tiện xu_thế này e rằng đa phằn người dùng sẽ không ưa_thích \"\n",
            "Toàn hàng trungkhi mua quên ko coi kĩ\n",
            "\" máy này có cái CPU k phải skylake là thấy không hay rồi \"\n",
            "\n",
            "==============================\n",
            "\n",
            "Compliment - LABEL = 0\n",
            "Dung dc sp tot cam on shop Đóng_gói sản_phẩm rất đẹp và chắc_chắn Chất_lượng sản_phẩm tuyệt_vời\n",
            "Chất_lượng sản_phẩm tuyệt_vời . _Son mịn nhưng khi đánh lên không như màu trên ảnh\n",
            "Chất_lượng sản_phẩm tuyệt_vời nhưng k có hộp k có dây giày đen k có tất\n",
            "Chất_lượng sản_phẩm tuyệt_vời có_điều không cứng_cáp với không cố_định dáng nói_chung đẹp hợp túi_tiền\n",
            "Đã nhận đc hàng rất nhanh mới đặt buổi tối mà trưa mai là có rồi = } } Đóng_gói sản_phẩm rất đẹp và chắc_chắn Shop phục_vụ rất tốt\n",
            "Hàng ship nhanh chất_lượng tốt tư_vấn nhiệt_tình ship rất đung size sẽ ủng_hộ shop nhìu ❤️\n",
            "Chất_lượng sản_phẩm tuyệt vời.y hình chụp.đáng tiền\n",
            "Hjhj shop giao hàng nhanh quá . Đẹp lắm ạ bé nhà m rất thích\n",
            "\" nhìn đẹp phết nhỉ .. \"\n",
            "Đóng_gói rất đẹp . Chất_lượng sản_phẩm rất tốt Chất_lượng sản_phẩm tuyệt_vời\n"
          ]
        }
      ],
      "source": [
        "print(\"Critical- LABEL = 1\")\n",
        "for text in df[df[\"label\"] == 1][\"text\"].values[:10]:\n",
        "  print(text)\n",
        "print()\n",
        "print(\"=\"*30)\n",
        "print()\n",
        "print(\"Compliment - LABEL = 0\")\n",
        "for text in df[df[\"label\"] == 0][\"text\"].values[:10]:\n",
        "  print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEeUvzE03mAB"
      },
      "source": [
        "We see that the above dataset has been applied Word Segment technique to separate words\n",
        "\n",
        "However, the above dataset has not been cleaned (delete emoji, special characters, ...)\n",
        "\n",
        "We will delete the special characters `: , = ...` but it should be noted not to delete the character `_` (which will spoil the result of the Word Segment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4VUL5_e0giZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def simple_preprocessing(text):\n",
        "    # Remove emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               \"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                               \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    text = emoji_pattern.sub(r'', text)\n",
        "    # Remove special characters excluding underscore (_) with regex python\n",
        "    text = re.sub(r'[^\\w\\s_]', '', text)\n",
        "\n",
        "    '''\n",
        "    Deleting special characters can lead to the excess spaces\n",
        "    for example \"huhu : ( (  buồn quá\" sẽ thành \"huhu     buồn quá\"\n",
        "    We will split the text in a space and then join it again to correct this case\n",
        "    '''\n",
        "\n",
        "    text = \" \".join(text.split())\n",
        "    text = text.strip().lower()\n",
        "    return text\n",
        "\n",
        "df[\"text\"] = df[\"text\"].apply(simple_preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfPotc6y5Rib",
        "outputId": "40631f60-8660-4fd9-8238-f78ff03c22ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Critical- LABEL = 1\n",
            "mình hơi thất_vọng 1 chút vì mình đã kỳ_vọng cuốn sách khá nhiều hi_vọng nó sẽ nói về việc học_tập của cách sinh_viên trường harvard ra sao những nỗ_lực của họ như_thế_nào 4h sáng tại_sao họ lại phải thức dậy vào thời_khắc đấy sau đó là cả một câu_chuyện ra sao cái mình thực_sự cần ở đây là câu_chuyện ẩn dấu trong đó để tự bản_thân mỗi người cảm_nhận và đi_sâu vào lòng người hơn còn cuốn sách này chỉ đơn_thuần là cuốn sách dạy kĩ_năng mà hầu_như sách nào cũng đã có buồn\n",
            "lần trước mình mua áo_gió màu hồng rất ok mà đợt này lại giao 2 cái áo_gió chất khác như vải mưa ý\n",
            "các siêu phẩm thấy cấu_hình toàn tựa tựa nhau ko còn sự đột_phá lớn nữa chỉ là nâng_cấp khác nhau về kiểu_dáng htc này vs giá trên thật lòng khó cạnh_tranh mạnh vs siêu phẩm khác chỉ dành cho fan của họ thôi\n",
            "đồng_hồ đẹp nhưng 1 cái đứt dây 1 cái k chạy mua ve phải sửa\n",
            "giao thiếu mình cái này rồi shop ơi t t\n",
            "không hài_lòng sản_phẩm cho lắm giặt lan đầu_tiên da nhoe màu hết rồi\n",
            "đồng_hồ thì đẹp thật nhưng tại_sao kim lúc chạy lúc đứng nhắn_tin thì ko trả_lời mấy bạn lưu_ý đừng mua nữa\n",
            "cũng hơi bất_tiện xu_thế này e rằng đa phằn người dùng sẽ không ưa_thích\n",
            "toàn hàng trungkhi mua quên ko coi kĩ\n",
            "máy này có cái cpu k phải skylake là thấy không hay rồi\n",
            "\n",
            "==============================\n",
            "\n",
            "Compliment - LABEL = 0\n",
            "dung dc sp tot cam on shop đóng_gói sản_phẩm rất đẹp và chắc_chắn chất_lượng sản_phẩm tuyệt_vời\n",
            "chất_lượng sản_phẩm tuyệt_vời _son mịn nhưng khi đánh lên không như màu trên ảnh\n",
            "chất_lượng sản_phẩm tuyệt_vời nhưng k có hộp k có dây giày đen k có tất\n",
            "chất_lượng sản_phẩm tuyệt_vời có_điều không cứng_cáp với không cố_định dáng nói_chung đẹp hợp túi_tiền\n",
            "đã nhận đc hàng rất nhanh mới đặt buổi tối mà trưa mai là có rồi đóng_gói sản_phẩm rất đẹp và chắc_chắn shop phục_vụ rất tốt\n",
            "hàng ship nhanh chất_lượng tốt tư_vấn nhiệt_tình ship rất đung size sẽ ủng_hộ shop nhìu\n",
            "chất_lượng sản_phẩm tuyệt vờiy hình chụpđáng tiền\n",
            "hjhj shop giao hàng nhanh quá đẹp lắm ạ bé nhà m rất thích\n",
            "nhìn đẹp phết nhỉ\n",
            "đóng_gói rất đẹp chất_lượng sản_phẩm rất tốt chất_lượng sản_phẩm tuyệt_vời\n"
          ]
        }
      ],
      "source": [
        "# Review results after preprocessing\n",
        "print(\"Critical- LABEL = 1\")\n",
        "for text in df[df[\"label\"] == 1][\"text\"].values[:10]:\n",
        "  print(text)\n",
        "print()\n",
        "print(\"=\"*30)\n",
        "print()\n",
        "print(\"Compliment - LABEL = 0\")\n",
        "for text in df[df[\"label\"] == 0][\"text\"].values[:10]:\n",
        "  print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2P_v4sp5e4n"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2R11DxA5mkO"
      },
      "source": [
        "We will split the dataset into 3 sets\n",
        "- Train\n",
        "- Validation\n",
        "- Test\n",
        "\n",
        "You should note: when performing Tokenizer and Embedding, you can only manipulate on the Train episode. This leads to when testing the model on the Validation and Test set will be able to occur the following cases:\n",
        "- In 2 episodes of Val-Test appear words that never appeared in the episode Train\n",
        "- In 2 episodes of Val-Test appear documents that are too long or too short for Train\n",
        "\n",
        "The above differences will lower the performance of model → this is the reason that you need to have 1 quality dataset so that the model can run well in real application\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX2xNzDn0kxg",
        "outputId": "80ca0c4a-1ef3-4121-c148-b398bb123c45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "(9651,) (9651,)\n",
            "Validation Set\n",
            "(3217,) (3217,)\n",
            "Test Set\n",
            "(3218,) (3218,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sentences, labels = df[\"text\"].values, df[\"label\"].values\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    sentences,\n",
        "    labels,\n",
        "    test_size=0.4,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    test_size=0.5,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        "    stratify=y_val\n",
        ")\n",
        "\n",
        "print(\"Train Set\")\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(\"Validation Set\")\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(\"Test Set\")\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fx8FLlN2OfC"
      },
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gj4oDUw8tGY"
      },
      "source": [
        "In this Assignment, we will use the `TextVectorization` layer of `tensorflow.keras` to turn the Tokenizer operation into 1 part of the model (in the Lab article, we Tokenizer first and then put it into the model)\n",
        "\n",
        "Before initializing the Tokenizer, we need to calculate the length and number of unique words of the documents in the Train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yFaUc2H_BF3"
      },
      "source": [
        "**Count unique words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "262vjBw09HGa",
        "outputId": "ad593892-4d25-4e45-a8a5-1ff737bc23d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9930\n"
          ]
        }
      ],
      "source": [
        "word_set = set()\n",
        "for text in x_train:\n",
        "  words = text.split()\n",
        "  for word in words:\n",
        "    if word not in word_set:\n",
        "      word_set.add(word)\n",
        "\n",
        "VOCAB_SIZE = len(word_set)\n",
        "print(VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zze45NIR_Eg6"
      },
      "source": [
        "**Count the average length of eachg text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-XD-s4h9TXC",
        "outputId": "e68b2363-ee5b-45ed-e103-806bdf576e48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0, 369, 17.793907367112215)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_word = []\n",
        "for text in x_train:\n",
        "  words = text.split()\n",
        "  count_word.append(len(words))\n",
        "\n",
        "min(count_word), max(count_word), sum(count_word)/len(count_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQCFIOK193xm"
      },
      "source": [
        "We see a problem when the value `min` is zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBLUSnSL9tZl",
        "outputId": "71090bd7-3e57-4814-82fd-2f4997385a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "for text in x_train:\n",
        "  if text == \"\":\n",
        "    print(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RQYX6X-cQz"
      },
      "source": [
        "Delete lines with null values in `x_train` and delete corresponding lines in `y_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQtA81I8-YQl"
      },
      "outputs": [],
      "source": [
        "new_train_text = []\n",
        "new_train_label = []\n",
        "\n",
        "for text, label in zip(x_train, y_train):\n",
        "  if text != \"\":\n",
        "    new_train_text.append(text)\n",
        "    new_train_label.append(label)\n",
        "\n",
        "x_train = np.array(new_train_text)\n",
        "y_train = np.array(new_train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQo-w2zr_Im7",
        "outputId": "b2f9df4b-268e-4678-a673-651b1671064c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 369, 17.799440298507463)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_word = []\n",
        "for text in x_train:\n",
        "  words = text.split()\n",
        "  count_word.append(len(words))\n",
        "\n",
        "min(count_word), max(count_word), sum(count_word)/ len(count_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5IdNzWy3teV"
      },
      "source": [
        "Do the same with test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYmxBFaj3nRe"
      },
      "outputs": [],
      "source": [
        "new_test_text = []\n",
        "new_test_label = []\n",
        "\n",
        "for text, label in zip(x_test, y_test):\n",
        "  if text != \"\":\n",
        "    new_test_text.append(text)\n",
        "    new_test_label.append(label)\n",
        "\n",
        "x_test = np.array(new_test_text)\n",
        "y_test = np.array(new_test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqJw9RW86FaW"
      },
      "outputs": [],
      "source": [
        "new_val_text = []\n",
        "new_val_label = []\n",
        "\n",
        "for text, label in zip(x_val, y_val):\n",
        "  if text != \"\":\n",
        "    new_val_text.append(text)\n",
        "    new_val_label.append(label)\n",
        "\n",
        "x_val = np.array(new_val_text)\n",
        "y_val = np.array(new_val_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmzSHtWD_8Fh"
      },
      "source": [
        "In fact, the `TextVectorization` layer will automatically calculate the number of unique words (plus 2 for `out_of_vocab` and `special` tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2nga5BcAK-G",
        "outputId": "924da3da-292d-4ac3-e5d7-28682b2dbfe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9932\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# We calculate 9930, here we leave 10k to see the result of the layer\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LENGTH = 50 # average length is 17\n",
        "\n",
        "tokenizer = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    standardize=None, # preprocessing already done above\n",
        "    output_mode=\"int\", # output list containing tokreprocess (representing words in the field)\n",
        "    output_sequence_length=MAX_LENGTH # padding or truncate until MAX_LENGTH\n",
        ")\n",
        "\n",
        "# Fit on x_train\n",
        "tokenizer.adapt(x_train)\n",
        "print(tokenizer.vocabulary_size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YFftYJzDy34"
      },
      "source": [
        "Update the variable `VOCAB_SIZE`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksQWzwiYD1-i"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = tokenizer.vocabulary_size() # 9932"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vwV_ZoiDNKR"
      },
      "source": [
        "### Pretrained Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs2taqVbDmMR"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "\n",
        "ft = fasttext.load_model(\"/content/drive/MyDrive/Colab Notebooks/ML-intensive/data/cc.vi.50.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3kbjd6ETSn"
      },
      "source": [
        "This pretrained Word Embedding will represent the word with 1 vector `50 dimensions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs2W5fKdEbXa",
        "outputId": "91c06b13-2497-4d8c-d37b-b0bc1300cc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.08987515  0.11855838 -0.041201   -0.08122422 -0.04498195 -0.07693475\n",
            "  0.01601385 -0.10124682  0.03174876  0.03258704  0.02468052  0.00593183\n",
            " -0.01430611  0.04422166  0.02866276 -0.01971636  0.01052842  0.01453072\n",
            " -0.01432774 -0.08909895 -0.06839065 -0.03624108  0.06818447  0.06247804\n",
            " -0.11234589  0.06176881  0.04748557 -0.02569062 -0.02754932  0.00407921\n",
            " -0.00562474 -0.04759934 -0.01732392  0.03452192  0.01076003  0.02103091\n",
            "  0.03082983  0.03875627  0.00951283 -0.03213377 -0.04992865  0.00212197\n",
            " -0.11983471 -0.00709106 -0.01203236 -0.01266732 -0.04353423 -0.00745085\n",
            "  0.03781988 -0.0106875 ]\n",
            "(50,)\n"
          ]
        }
      ],
      "source": [
        "text = \"đẹp_trai\"\n",
        "embedding = ft[text]\n",
        "print(embedding)\n",
        "print(embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmLAlvUfKtIz"
      },
      "source": [
        "#### TODO 1\n",
        "\n",
        "We will write the algorithm described in the Pre-Class article to derive vector embedding for each word in the dictionary\n",
        "- Initalize empty  list `embeddings`\n",
        "- Loop through each word in the dictionary\n",
        "  - Retrieve a list of words to repeat with `tokenizer.get_vocabulary(include_special_tokens=True)`\n",
        "  - Use `tqdm` to display progress bar `tqdm(tokenizer.get_vocabulary(include_special_tokens=True))`\n",
        "- if the word exists in Pretrained Embedding (use the `in ft` command to check)\n",
        "  - add it to `embeddings`\n",
        "- If not exist\n",
        "  - Intialize randomly a vector of 50 features `np.random.uniform`, ranging from `-0.05` to `0.05` and then add into `embeddings`\n",
        "- Convert `embeddings` into `numpy array` and print the shape to test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl22A2IK8AYc",
        "outputId": "f9d16b9d-041c-4935-8f2f-ec72a0b3c87e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9930"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.get_vocabulary(include_special_tokens=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOwy1BfJ8NjK",
        "outputId": "980eca2c-b335-40b7-977b-a6ff08370ebc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9932"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer.get_vocabulary(include_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkXfKkr08fWi",
        "outputId": "a3483575-360e-45a6-b7d8-969bcfbf5c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "if \"đẹp_trai\" in ft:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b8b7f787edaa46989c5074a3fea2eefe",
            "c0fe11b752a84e71b56517ee065a46af",
            "72aa1418312c40f7bca2ea36cfdc2a96",
            "71c62c7ab8e14bc7b807a0a86af612b3",
            "a58f736a70f043b2ad65b1061de6dcd0",
            "c6af19c8bbff4920937067ab9e7fec8a",
            "3368f63fc1b14fb590a3513541125bc8",
            "3948d3235d2b486d9d10edd0c48d6987",
            "7a240f0ac5604403a6d7029e57abe6cf",
            "f9f81354bf464eb8949a8bdbf32bfe2c",
            "d3c3ee7e85ca4afa8d16dfb06ac92eee"
          ]
        },
        "id": "Yqm8A9JIEhZy",
        "outputId": "f07ca50e-0599-4110-92b2-ed2994815492"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8b7f787edaa46989c5074a3fea2eefe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9932 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(9932, 50)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "embeddings = []\n",
        "\n",
        "for word in tqdm(tokenizer.get_vocabulary(include_special_tokens=True)):\n",
        "  if word in ft:\n",
        "    embeddings.append(ft[word])\n",
        "  else:\n",
        "    embeddings.append(np.random.uniform(low=-0.5, high=0.5, size=(50,)))\n",
        "\n",
        "embeddings = np.array(embeddings)\n",
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urmPMVShG2iW"
      },
      "source": [
        "Initialize layer `Embedding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMDTNGQ7G5uK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.initializers import Constant # to initialize the available Embedding = weight layer\n",
        "\n",
        "# Include the embeddings variable as the weight of the layer\n",
        "embedding_layer = Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    50,\n",
        "    embeddings_initializer=Constant(embeddings), # plug in the embeddings variable as the weight of the layer\n",
        "    name=\"embedding\" # Name the layer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SmX2YJNOYjy"
      },
      "source": [
        "### Simple Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIt7WpCK5ovl",
        "outputId": "e1893956-ba2d-4883-c67e-d6b82c448672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 50)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 50, 50)            496600    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                2656      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                528       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 499,801\n",
            "Trainable params: 499,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, SimpleRNN, LSTM, GRU\n",
        "from tensorflow import string\n",
        "\n",
        "\n",
        "'''\n",
        "Pipeline:\n",
        "- input layer receive documents (shape=1, dtype=str)\n",
        "- tokenizer\n",
        "- embedding\n",
        "- RNN & MLP\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(1,), dtype=string))\n",
        "xmodel.add(tokenizer)\n",
        "model.add(embedding_layer)\n",
        "model.add(SimpleRNN(32))\n",
        "\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zUWPNub-Q1d",
        "outputId": "c8419a73-3c78-4c69-e239-4864f3e44b42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "302/302 [==============================] - 64s 191ms/step - loss: 0.6701 - accuracy: 0.6015 - val_loss: 0.6665 - val_accuracy: 0.6052\n",
            "Epoch 2/5\n",
            "302/302 [==============================] - 35s 116ms/step - loss: 0.6596 - accuracy: 0.6106 - val_loss: 0.6616 - val_accuracy: 0.6080\n",
            "Epoch 3/5\n",
            "302/302 [==============================] - 28s 92ms/step - loss: 0.6454 - accuracy: 0.6188 - val_loss: 0.6674 - val_accuracy: 0.6049\n",
            "Epoch 4/5\n",
            "302/302 [==============================] - 29s 95ms/step - loss: 0.6361 - accuracy: 0.6251 - val_loss: 0.6792 - val_accuracy: 0.6040\n",
            "Epoch 5/5\n",
            "302/302 [==============================] - 29s 97ms/step - loss: 0.6266 - accuracy: 0.6358 - val_loss: 0.6035 - val_accuracy: 0.7128\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e440bd72fb0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'\n",
        "              ])\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wG-jfhj_5pH"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)\n",
        "y_pred_test = model.predict(x_test) >= 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ctWx5-i_z2q"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, fmt=\"d\")\n",
        "plt.show()\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5qKLDAQLkb5"
      },
      "source": [
        "#### TODO 2\n",
        "\n",
        "Now it`s your turn, use more complex models:\n",
        "1. Stacked Biderectional RNN: oftenly, only 2 to 3 layers should be stacked\n",
        "2. Replace the RNN in model 1 with LSTM or GRU and train again\n",
        "\n",
        "**Note: you need to reinitialize the 'Embedding' layer from the 'embeddings' variable when creating a new model (as the current 'Embedding' layer has already been trained)**\n",
        "\n",
        "There are 1 techniques to train the model better when using the Pretrained Model::\n",
        "- Freezing the pretrained layer (in this tutorial the `Embedding` layer), i.e. not updating the weight of this layer during training\n",
        "- Train the model\n",
        "- Open the pretrained layers, and continue training with a small `learning_rate`.\n",
        "\n",
        "We will learn about the above technique later, but you can try it\n",
        "\n",
        "```python\n",
        "# Initialize embedding\n",
        "embedding_layer = Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    50,\n",
        "    embeddings_initializer=Constant(embeddings),\n",
        "    name=\"embedding\"\n",
        ")\n",
        "\n",
        "# Freeze weights\n",
        "embedding_layer.trainable = False\n",
        "\n",
        "# Create the model\n",
        "# Start training process\n",
        "...\n",
        "# Unfreeze weights\n",
        "embedding_layer.trainable = True\n",
        "\n",
        "# re-compile model (compile only, not recreate) and use smaller learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=smaller_lr))\n",
        "model.fit(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXNe5GlrN4rK",
        "outputId": "c23f9517-80a0-43e6-b470-e0f6efa54b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "302/302 [==============================] - 43s 100ms/step - loss: 0.3946 - accuracy: 0.8164 - val_loss: 0.2911 - val_accuracy: 0.8834\n",
            "Epoch 2/5\n",
            "302/302 [==============================] - 12s 39ms/step - loss: 0.2331 - accuracy: 0.9101 - val_loss: 0.2551 - val_accuracy: 0.8949\n",
            "Epoch 3/5\n",
            "302/302 [==============================] - 9s 30ms/step - loss: 0.1778 - accuracy: 0.9334 - val_loss: 0.2733 - val_accuracy: 0.8934\n",
            "Epoch 4/5\n",
            "302/302 [==============================] - 8s 27ms/step - loss: 0.1409 - accuracy: 0.9516 - val_loss: 0.2961 - val_accuracy: 0.8893\n",
            "Epoch 5/5\n",
            "302/302 [==============================] - 7s 22ms/step - loss: 0.1174 - accuracy: 0.9621 - val_loss: 0.3195 - val_accuracy: 0.8813\n",
            "Epoch 1/5\n",
            "302/302 [==============================] - 43s 110ms/step - loss: 0.0920 - accuracy: 0.9700 - val_loss: 0.3745 - val_accuracy: 0.8841\n",
            "Epoch 2/5\n",
            "302/302 [==============================] - 12s 38ms/step - loss: 0.0769 - accuracy: 0.9755 - val_loss: 0.4313 - val_accuracy: 0.8847\n",
            "Epoch 3/5\n",
            "302/302 [==============================] - 8s 28ms/step - loss: 0.0672 - accuracy: 0.9803 - val_loss: 0.4790 - val_accuracy: 0.8729\n",
            "Epoch 4/5\n",
            "302/302 [==============================] - 8s 25ms/step - loss: 0.0602 - accuracy: 0.9821 - val_loss: 0.4900 - val_accuracy: 0.8778\n",
            "Epoch 5/5\n",
            "302/302 [==============================] - 7s 23ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 0.5347 - val_accuracy: 0.8744\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e42ec702e60>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR SOLUTION\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import string\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Intialize Embedding layer\n",
        "embedding_layer = layers.Embedding(\n",
        "    VOCAB_SIZE,\n",
        "    50,\n",
        "    embeddings_initializer = Constant(embeddings),\n",
        "    name=\"embedding\"\n",
        ")\n",
        "\n",
        "# Freeze weights\n",
        "embedding_layer.trainble = False\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(layers.Input(shape=(1,), dtype=string))\n",
        "model.add(tokenizer)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "# Due to stacking to layers LSTM -> return_sequences=True is required in the first layer\n",
        "model.add(layers.Bidirectional(layers.LSTM(32, return_sequences=True)))\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5)\n",
        "\n",
        "# Unfreeze Embeddding\n",
        "embedding_layer.trainable = True\n",
        "\n",
        "# optimizer\n",
        "adam = Adam(0.0005)\n",
        "\n",
        "# re-compile and re-fit the model with smaller learning rate\n",
        "model.compile(optimizer=adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3368f63fc1b14fb590a3513541125bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3948d3235d2b486d9d10edd0c48d6987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c62c7ab8e14bc7b807a0a86af612b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f81354bf464eb8949a8bdbf32bfe2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c3ee7e85ca4afa8d16dfb06ac92eee",
            "value": " 9932/9932 [01:40&lt;00:00, 58.79it/s]"
          }
        },
        "72aa1418312c40f7bca2ea36cfdc2a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3948d3235d2b486d9d10edd0c48d6987",
            "max": 9932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a240f0ac5604403a6d7029e57abe6cf",
            "value": 9932
          }
        },
        "7a240f0ac5604403a6d7029e57abe6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a58f736a70f043b2ad65b1061de6dcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b7f787edaa46989c5074a3fea2eefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0fe11b752a84e71b56517ee065a46af",
              "IPY_MODEL_72aa1418312c40f7bca2ea36cfdc2a96",
              "IPY_MODEL_71c62c7ab8e14bc7b807a0a86af612b3"
            ],
            "layout": "IPY_MODEL_a58f736a70f043b2ad65b1061de6dcd0"
          }
        },
        "c0fe11b752a84e71b56517ee065a46af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6af19c8bbff4920937067ab9e7fec8a",
            "placeholder": "​",
            "style": "IPY_MODEL_3368f63fc1b14fb590a3513541125bc8",
            "value": "100%"
          }
        },
        "c6af19c8bbff4920937067ab9e7fec8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c3ee7e85ca4afa8d16dfb06ac92eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f81354bf464eb8949a8bdbf32bfe2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
