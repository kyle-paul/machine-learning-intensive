

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Session 1: Coding Solution &#8212; Machine Learning Intensive</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/Session1/S1_SOL';</script>
    <link rel="canonical" href="https://kyle-paul.github.io/machine-learning-intensive/book/Session1/S1_SOL.html" />
    <link rel="shortcut icon" href="../../_static/avatar.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Session 1: Revision" href="Session%201%20Revision.html" />
    <link rel="prev" title="Session 1: Assigment" href="S1_ASM.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Preclass%20Session%201.html"><strong>Preclass Session 1: Representation</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="S1_Lab_Representation.html">Session 1: Representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="S1_ASM.html">Session 1: Assigment</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Session 1: Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="Session%201%20Revision.html"><strong>Session 1: Revision</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session2/Preclass%20Session%202.html"><strong>Preclass Session 2: Linear Model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session2/S2_Lab_LinearModel.html">Session 2: Linear Model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session2/S2_ASM.html">Session 2: Assigment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session2/S2_SOL.html">Session 2: Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session2/Session%202%20Revision.html">Session 2: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session3/Preclass%20Session%203.html"><strong>Preclass Session 3: Recommender System</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session3/S3_Lab_RecSys.html">Sesion 3: Recommender System</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session3/S3_ASM.html">Session 3: Assigment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session3/S3_SOL.html">Session 3: Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session3/Session%203%20Revision.html">Session 3: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session4/Preclass%20Session%204.html"><strong>Preclass Session 4: NonLinear Predictor</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session4/S4_Lab_NonLinearPredictors.html">Session 4: Nonlinear Predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session4/S4_ASM.html">Session 4: Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session4/S4_SOL.html">Session 4: Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session4/Session%204%20Revision.html">Session 4: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session5/Preclass%20Session%205.html"><strong>Preclass Session 5: Optimization</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session5/S5_Lab_Optimization.html">Session 5: Optimization</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session5/S5_ASM.html">Session 5: Assigment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session5/S5_SOL.html">Session 5: Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session5/Session%205%20Revision.html">Session 5: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session6/Preclass%20Session%206.html"><strong>Preclass Session 6: Metrics and Losses</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session6/S6_Lab_Metrics%26Losses.html">Session 6: Metrics &amp; Losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session6/S6_ASM.html">Session 6: Assignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session6/S6_SOL.html">Session 6: Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session6/Session%206%20Revision.html">Session 6: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session7/Midterm%20Theory%20Test.html"><strong>Theory Midterm Test</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session7/Midterm%20Theory%20Solution.html">Theory Midterm Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session7/S7_MidTerm_TEST.html">Session 7: Midterm Coding Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session7/S7_MidTerm_SOL.html">Session 7: Midterm Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session8/Preclass%20Session%208.html"><strong>Preclass Session 8: Convolutional Neural Network</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session8/S8_Lab_CNN.html">Session 8: Convolutional Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../Session8/S8_ASM.html">Session 8: Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session8/S8_SOL.html">Session 8: Coding Solution</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session8/Session%208%20Revision.html">Session 8: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session9/Preclass%20Session%209.html"><strong>Preclass Session 9: Natural Language Processing</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="../Session9/S9_LAB_RNN.html">Session 9 - Natural Language Processing</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Session9/S9_ASM.html">Session 9: Assignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session9/S9_SOL.html">Session 9: Coding Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session9/Session%209%20Revision.html">Session: 9 Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session10/Preclass%20Session%2010.html"><strong>Preclass Session 10: MDP Planning</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session10/S10_LAB_MDP_PLANNING.html">Session 10 - MDP Planning</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session10/S10_ASM.html">Session 10: Assigment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session10/S10_SOL.html">Session 10: Coding Solution</a></li>

<li class="toctree-l1"><a class="reference internal" href="../Session10/Session%2010%20Revision.html">Session 10: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session11/Preclass%20Session%2011.html"><strong>Preclass Session 11: Reinforcement Learning</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="../Session11/S11_LAB_Q_Learning.html">Session 11: Q Learning</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Session11/S11_SOL.html">Session 11: Coding Solution</a></li>


<li class="toctree-l1"><a class="reference internal" href="../Session11/Session%2011%20Revision.html">Session 11: Revision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session12/Final%20Test%20Theory.html"><strong>Session 12: final theory test</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session12/S12_FinalExam_TEST.html">Sesssion 12: Final Coding Test</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Session12/S12_FinalExam_SOL.html">Sesssion 12: Final Coding Solution</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/kyle-paul/machine-learning-intensive/master?urlpath=tree/book/Session1/S1_SOL.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/kyle-paul/machine-learning-intensive/blob/master/book/Session1/S1_SOL.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/kyle-paul/machine-learning-intensive" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kyle-paul/machine-learning-intensive/edit/main/book/Session1/S1_SOL.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kyle-paul/machine-learning-intensive/issues/new?title=Issue%20on%20page%20%2Fbook/Session1/S1_SOL.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/book/Session1/S1_SOL.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Session 1: Coding Solution</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-face-recognition-with-pca-and-knn-7-popints">Problem 1: Face Recognition with PCA and KNN (7 popints)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-dataset">Prepare the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-the-data">Analyze the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-pca-to-reduce-data-dimension-and-draw-embedding-space">Use PCA to reduce data dimension and draw Embedding Space</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-1">TODO 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-2">TODO 2</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-test-split">Train Test Split</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-3">TODO 3</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction-with-pca">Feature Extraction with PCA</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-4">TODO 4</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-knn">Classification with KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-5">TODO 5</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-6">TODO 6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-7">TODO 7</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2-console-game-semantris-3-points">Problem 2: Console game Semantris (3 points)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guildance">Guildance</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="session-1-coding-solution">
<h1><a class="toc-backref" href="#id1" role="doc-backlink">Session 1: Coding Solution</a><a class="headerlink" href="#session-1-coding-solution" title="Permalink to this heading">#</a></h1>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#session-1-coding-solution" id="id1">Session 1: Coding Solution</a></p>
<ul>
<li><p><a class="reference internal" href="#problem-1-face-recognition-with-pca-and-knn-7-popints" id="id2">Problem 1: Face Recognition with PCA and KNN (7 popints)</a></p>
<ul>
<li><p><a class="reference internal" href="#prepare-the-dataset" id="id3">Prepare the dataset</a></p></li>
<li><p><a class="reference internal" href="#analyze-the-data" id="id4">Analyze the data</a></p></li>
<li><p><a class="reference internal" href="#use-pca-to-reduce-data-dimension-and-draw-embedding-space" id="id5">Use PCA to reduce data dimension and draw Embedding Space</a></p>
<ul>
<li><p><a class="reference internal" href="#todo-1" id="id6">TODO 1</a></p></li>
<li><p><a class="reference internal" href="#todo-2" id="id7">TODO 2</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#train-test-split" id="id8">Train Test Split</a></p>
<ul>
<li><p><a class="reference internal" href="#todo-3" id="id9">TODO 3</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#feature-extraction-with-pca" id="id10">Feature Extraction with PCA</a></p>
<ul>
<li><p><a class="reference internal" href="#todo-4" id="id11">TODO 4</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#classification-with-knn" id="id12">Classification with KNN</a></p>
<ul>
<li><p><a class="reference internal" href="#todo-5" id="id13">TODO 5</a></p></li>
<li><p><a class="reference internal" href="#todo-6" id="id14">TODO 6</a></p></li>
<li><p><a class="reference internal" href="#todo-7" id="id15">TODO 7</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#problem-2-console-game-semantris-3-points" id="id16">Problem 2: Console game Semantris (3 points)</a></p></li>
<li><p><a class="reference internal" href="#guildance" id="id17">Guildance</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="problem-1-face-recognition-with-pca-and-knn-7-popints">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Problem 1: Face Recognition with PCA and KNN (7 popints)</a><a class="headerlink" href="#problem-1-face-recognition-with-pca-and-knn-7-popints" title="Permalink to this heading">#</a></h2>
<p>In this problem, we will use PCA to extract features and then use KNN model to give predictions based on extracted features.</p>
<section id="prepare-the-dataset">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Prepare the dataset</a><a class="headerlink" href="#prepare-the-dataset" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="nn">px</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_lfw_people</span><span class="p">(</span><span class="n">min_faces_per_person</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="analyze-the-data">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Analyze the data</a><a class="headerlink" href="#analyze-the-data" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;data&#39;, &#39;images&#39;, &#39;target&#39;, &#39;target_names&#39;, &#39;DESCR&#39;])
</pre></div>
</div>
</div>
</div>
<p>Some important <code class="docutils literal notranslate"><span class="pre">key</span></code> you need to consider when solving this problem:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">images</span></code>: the grayscale image dataset (already normalized)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: the grayscale image dataset already normalized). Each image is flattened into one vector</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target</span></code>: label of each image/face (type <code class="docutils literal notranslate"><span class="pre">int</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target_names</span></code>: name of each face (type <code class="docutils literal notranslate"><span class="pre">str</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">data</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">target_names</span>
<span class="n">num_image</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of images:&quot;</span><span class="p">,</span> <span class="n">num_image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Height of each image:&quot;</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Width of each image:&quot;</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data shape:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of images: 1288
Height of each image: 100
Width of each image: 75
Data shape: (1288, 7500)
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s see the names of faces included in the dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of people in the dataset:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">target_names</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of people in the dataset: 7
[&#39;Ariel Sharon&#39; &#39;Colin Powell&#39; &#39;Donald Rumsfeld&#39; &#39;George W Bush&#39;
 &#39;Gerhard Schroeder&#39; &#39;Hugo Chavez&#39; &#39;Tony Blair&#39;]
</pre></div>
</div>
</div>
</div>
<p>The variable <code class="docutils literal notranslate"><span class="pre">target</span></code> contains the labels of the above 7 faces, numbered from 0 to 6</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">ids</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> images of </span><span class="si">{</span><span class="n">target_names</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5 6 3 ... 5 3 5]
------------------------------
There are 77 images of Ariel Sharon
There are 236 images of Colin Powell
There are 121 images of Donald Rumsfeld
There are 530 images of George W Bush
There are 109 images of Gerhard Schroeder
There are 71 images of Hugo Chavez
There are 144 images of Tony Blair
</pre></div>
</div>
</div>
</div>
<p>Visualization</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target_with_name</span> <span class="o">=</span> <span class="p">[</span><span class="n">target_names</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">target</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">target_with_name</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">target_with_name</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><html>
<head><meta charset="utf-8" /></head>
<body>
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-2.18.2.min.js"></script>                <div id="9e243897-a8cf-4525-99c6-3277b29d9083" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("9e243897-a8cf-4525-99c6-3277b29d9083")) {                    Plotly.newPlot(                        "9e243897-a8cf-4525-99c6-3277b29d9083",                        [{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Hugo Chavez<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Hugo Chavez","marker":{"color":"#636efa","pattern":{"shape":""}},"name":"Hugo Chavez","offsetgroup":"Hugo Chavez","orientation":"v","showlegend":true,"x":["Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez","Hugo Chavez"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Tony Blair<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Tony Blair","marker":{"color":"#EF553B","pattern":{"shape":""}},"name":"Tony Blair","offsetgroup":"Tony Blair","orientation":"v","showlegend":true,"x":["Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair","Tony Blair"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=George W Bush<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"George W Bush","marker":{"color":"#00cc96","pattern":{"shape":""}},"name":"George W Bush","offsetgroup":"George W Bush","orientation":"v","showlegend":true,"x":["George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush","George W Bush"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Colin Powell<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Colin Powell","marker":{"color":"#ab63fa","pattern":{"shape":""}},"name":"Colin Powell","offsetgroup":"Colin Powell","orientation":"v","showlegend":true,"x":["Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell","Colin Powell"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Ariel Sharon<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Ariel Sharon","marker":{"color":"#FFA15A","pattern":{"shape":""}},"name":"Ariel Sharon","offsetgroup":"Ariel Sharon","orientation":"v","showlegend":true,"x":["Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon","Ariel Sharon"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Gerhard Schroeder<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Gerhard Schroeder","marker":{"color":"#19d3f3","pattern":{"shape":""}},"name":"Gerhard Schroeder","offsetgroup":"Gerhard Schroeder","orientation":"v","showlegend":true,"x":["Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder","Gerhard Schroeder"],"xaxis":"x","yaxis":"y","type":"histogram"},{"alignmentgroup":"True","bingroup":"x","hovertemplate":"color=Donald Rumsfeld<br>x=%{x}<br>count=%{y}<extra></extra>","legendgroup":"Donald Rumsfeld","marker":{"color":"#FF6692","pattern":{"shape":""}},"name":"Donald Rumsfeld","offsetgroup":"Donald Rumsfeld","orientation":"v","showlegend":true,"x":["Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld","Donald Rumsfeld"],"xaxis":"x","yaxis":"y","type":"histogram"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"x"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"count"}},"legend":{"title":{"text":"color"},"tracegroupgap":0},"margin":{"t":60},"barmode":"relative"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('9e243897-a8cf-4525-99c6-3277b29d9083');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>
</body>
</html></div></div>
</div>
<p>Visualize 5 random images of 5 person</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_people</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">n_image</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_people</span><span class="p">,</span> <span class="n">n_image</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_people</span><span class="p">):</span>
  <span class="n">current_id_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">target</span> <span class="o">==</span> <span class="n">row</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">random_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">current_id_indices</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_image</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_image</span><span class="p">):</span>
    <span class="n">current_ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span>
    <span class="n">current_ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">current_ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

    <span class="n">image_index</span> <span class="o">=</span> <span class="n">random_indices</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
    <span class="n">current_ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">image_index</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">current_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">target_names</span><span class="p">[</span><span class="n">row</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/abd9cb5d3944d3c1b1f40f0aee7ca2ee90eace7ad74c4e086237655fa4cbfb91.png" src="../../_images/abd9cb5d3944d3c1b1f40f0aee7ca2ee90eace7ad74c4e086237655fa4cbfb91.png" />
</div>
</div>
</section>
<section id="use-pca-to-reduce-data-dimension-and-draw-embedding-space">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Use PCA to reduce data dimension and draw Embedding Space</a><a class="headerlink" href="#use-pca-to-reduce-data-dimension-and-draw-embedding-space" title="Permalink to this heading">#</a></h3>
<section id="todo-1">
<h4><a class="toc-backref" href="#id6" role="doc-backlink">TODO 1</a><a class="headerlink" href="#todo-1" title="Permalink to this heading">#</a></h4>
<p>Use PCA to reduce the dimension of the data set to 3 dimensions, then print out the amount of information retained.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pca.explained_variance_ratio_</span></code> is the percentage of variance explained by each of the principal components. It tells you how much information (variance) can be attributed to each of the components. The sum of all the ratios is equal to 1.0.</p></li>
<li><p>For example, if you have two components, and the output is <code class="docutils literal notranslate"><span class="pre">[0.8,</span> <span class="pre">0.2]</span></code>, it means that the first component explains 80% of the variance in the data, and the second component explains 20% of the variance.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">pca.explained_variance_ratio_</span></code> is calculated by dividing the <code class="docutils literal notranslate"><span class="pre">pca.explained_variance_</span></code> by the sum of all the variances. The <code class="docutils literal notranslate"><span class="pre">pca.explained_variance_</span></code> is the eigenvalue of each component, which measures how much of the variance of the data is along that component.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The amount of retained information:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The amount of retained information: [0.20046061 0.13598016 0.06750589]
</pre></div>
</div>
</div>
</div>
<p>We see from the above results</p>
<ul class="simple">
<li><p>1st component explains 20.05% of the variance in the data</p></li>
<li><p>2nd component explains 13.60% of the variance in the data</p></li>
<li><p>3rd component explains 6.75% of the variance in the data</p></li>
</ul>
<p>Sum is 40.4% which means there are 59.6% of the variance that is not captured by these three components <span class="math notranslate nohighlight">\(â†’\)</span>, we need to increase the components to get a better representation of the data.</p>
<p>But when we need to plot the representation, we should only use 3 components to plot on 3D graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components:&#39;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of Principal Components:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Principal Components: 3
Shape of Principal Components: (3, 7500)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># transform the the data</span>
<span class="n">embed_3d</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="todo-2">
<h4><a class="toc-backref" href="#id7" role="doc-backlink">TODO 2</a><a class="headerlink" href="#todo-2" title="Permalink to this heading">#</a></h4>
<p>DÃ¹ng <code class="docutils literal notranslate"><span class="pre">plotly.express</span></code> Ä‘á»ƒ váº½ Ä‘á»“ thá»‹ <code class="docutils literal notranslate"><span class="pre">scatter_3d</span></code> trÃªn bá»™ dá»¯ liá»‡u 3 chiá»u, tÃ´ mÃ u cÃ¡c cháº¥m trÃ²n theo tÃªn ngÆ°á»i (dÃ¹ng biáº¿n <code class="docutils literal notranslate"><span class="pre">target_with_name</span></code> cÃ³ sáºµn á»Ÿ trÃªn)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;principal_component_1&quot;</span><span class="p">:</span> <span class="n">embed_3d</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
    <span class="s2">&quot;principal_component_2&quot;</span><span class="p">:</span> <span class="n">embed_3d</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;principal_component_3&quot;</span><span class="p">:</span> <span class="n">embed_3d</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
<span class="p">})</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="o">.</span><span class="n">scatter_3d</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s2">&quot;principal_component_1&quot;</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s2">&quot;principal_component_2&quot;</span><span class="p">,</span>
    <span class="n">z</span><span class="o">=</span><span class="s2">&quot;principal_component_3&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="n">target_with_name</span>
<span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><html>
<head><meta charset="utf-8" /></head>
<body>
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-2.18.2.min.js"></script>                <div id="c196d917-af3c-4615-8356-27f54cd14c67" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("c196d917-af3c-4615-8356-27f54cd14c67")) {                    Plotly.newPlot(                        "c196d917-af3c-4615-8356-27f54cd14c67",                        [{"hovertemplate":"color=Hugo Chavez<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Hugo Chavez","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"Hugo Chavez","scene":"scene","showlegend":true,"x":[-2.6629714965820312,7.5980072021484375,2.598985195159912,2.480900764465332,4.4646782875061035,6.250636577606201,10.360565185546875,-1.5129008293151855,9.57957649230957,2.393855094909668,-4.454582691192627,1.7307360172271729,8.868623733520508,3.3850924968719482,1.7613701820373535,-2.9970521926879883,-6.435657978057861,-6.160819053649902,0.3105228841304779,9.565098762512207,3.553161382675171,6.533537864685059,7.177764892578125,4.8535895347595215,-0.4750424027442932,5.110012054443359,12.46492862701416,1.7498303651809692,0.6232766509056091,-8.886366844177246,-0.14097222685813904,-7.10138463973999,-0.46540623903274536,-1.3740044832229614,-1.2032568454742432,0.5113484263420105,-6.750288486480713,7.544349670410156,-3.9771933555603027,8.706860542297363,-3.7308707237243652,4.7497968673706055,1.7517677545547485,4.2063984870910645,9.381065368652344,8.314275741577148,4.272217273712158,9.64661979675293,2.0222244262695312,9.63079833984375,-0.6519001722335815,-10.373541831970215,-0.24789705872535706,17.040916442871094,10.137930870056152,-4.8423237800598145,1.6819214820861816,5.52587366104126,3.0150563716888428,5.512236595153809,7.1648430824279785,-1.8243300914764404,8.251997947692871,8.219091415405273,-6.593321800231934,-0.12737461924552917,-1.8364473581314087,11.69477367401123,6.0977044105529785,7.057333946228027,2.515887498855591],"y":[0.9469977021217346,0.7200225591659546,-2.598968982696533,2.2241904735565186,-9.081073760986328,7.4521684646606445,2.3062667846679688,-0.8709349632263184,2.805757522583008,-2.48638653755188,2.2165110111236572,-0.523138701915741,1.6711430549621582,-2.652940034866333,-2.661653757095337,2.553933620452881,-2.1354448795318604,0.8715198636054993,0.10022427141666412,-0.8327441215515137,-3.160728693008423,-10.6480712890625,5.728016376495361,0.9207003116607666,0.3117671012878418,2.291731357574463,2.32198166847229,-1.6707022190093994,-1.5927199125289917,3.673828125,-0.5913538336753845,0.2973194420337677,0.6669593453407288,-3.589294672012329,8.878716468811035,-0.03446432948112488,0.05010820925235748,-6.218082904815674,7.701094150543213,-0.5814171433448792,-4.733234882354736,-0.9145995378494263,2.315638542175293,-0.16904348134994507,1.8648372888565063,-1.0152573585510254,-2.2286198139190674,3.3900485038757324,0.028089135885238647,-1.0011054277420044,5.686457633972168,2.8584508895874023,2.6192212104797363,1.441846251487732,-3.343886375427246,0.39029425382614136,1.10141921043396,-3.8408477306365967,-6.379734992980957,3.2299160957336426,0.7759226560592651,2.57149600982666,2.0841121673583984,-5.695025444030762,4.985562324523926,2.226235866546631,-2.7664794921875,-4.839189052581787,0.27498865127563477,2.3530125617980957,-0.6343175768852234],"z":[1.0355355739593506,-4.23853874206543,-5.209737777709961,3.026172161102295,2.669212818145752,-3.2802982330322266,-0.869077205657959,-0.9959598183631897,1.8239250183105469,1.6773309707641602,2.806328296661377,1.1286942958831787,0.33501821756362915,6.743180274963379,3.173494815826416,0.05783236399292946,1.1442209482192993,-3.163517475128174,3.257063865661621,-1.4131115674972534,1.7346107959747314,6.575477600097656,-5.5455474853515625,-4.257486820220947,-0.8399579524993896,-4.350276947021484,-2.3178703784942627,0.1428346186876297,-1.122353434562683,0.2775586247444153,2.8696165084838867,-3.2812352180480957,-1.9068530797958374,2.0108048915863037,1.8376662731170654,3.6806387901306152,1.0264899730682373,2.8676295280456543,8.567959785461426,0.266085147857666,3.7514281272888184,-2.1119985580444336,-4.404756546020508,-2.603769063949585,-2.362929344177246,-2.2423293590545654,-0.39809101819992065,0.4563269019126892,1.790224552154541,1.878615379333496,0.4530649185180664,-5.4427385330200195,1.3677563667297363,-1.2625583410263062,-4.881648063659668,-0.21141639351844788,7.156100749969482,-2.989232301712036,-0.9249990582466125,0.8758938312530518,2.986356019973755,-4.244084358215332,0.6688549518585205,-1.4681991338729858,-4.345824241638184,9.272928237915039,2.2834150791168213,-6.1320672035217285,-4.5338969230651855,-1.6968164443969727,2.3533997535705566],"type":"scatter3d"},{"hovertemplate":"color=Tony Blair<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Tony Blair","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"Tony Blair","scene":"scene","showlegend":true,"x":[4.216794013977051,-7.720839023590088,0.5134021639823914,-4.8138651847839355,0.8376631736755371,-6.384213447570801,0.19903458654880524,-0.11442448198795319,-3.6511240005493164,-1.7652180194854736,2.98311448097229,-5.174729824066162,-4.361485004425049,-5.803992748260498,-3.6385140419006348,0.44169798493385315,1.7077137231826782,-9.876401901245117,10.48646354675293,-4.063088417053223,-5.14346981048584,-6.024925708770752,-7.492627143859863,-2.9842660427093506,0.232571080327034,-2.7814929485321045,6.49919319152832,-7.12190055847168,-7.408124923706055,-5.741926193237305,-4.806789875030518,3.3797669410705566,4.538254737854004,-4.739012241363525,0.34722793102264404,-0.6365551948547363,-5.115522384643555,4.277267932891846,-1.9748448133468628,-12.250328063964844,-6.344597339630127,-2.4491844177246094,2.4248368740081787,-4.987759590148926,-5.221973419189453,-0.209294855594635,-4.233761787414551,-1.2360038757324219,-0.3162999749183655,-5.188916206359863,-9.559996604919434,-6.322262287139893,-1.993796467781067,3.153092384338379,2.2552497386932373,-4.215936660766602,3.694730520248413,5.166247844696045,-10.735719680786133,2.2320802211761475,-5.161186218261719,-1.0345044136047363,-4.17154598236084,0.8637269139289856,-12.910626411437988,8.939800262451172,0.6023751497268677,-2.865018367767334,-8.795083045959473,-12.020167350769043,-1.14602792263031,0.5361922383308411,-2.1156859397888184,3.375627040863037,11.68413257598877,-5.048271179199219,-2.216423511505127,0.8442005515098572,5.363397121429443,-4.7978596687316895,5.71415376663208,-6.766826152801514,4.12427282333374,-3.5290167331695557,-8.423027992248535,-2.4594004154205322,-0.1632353514432907,-1.1997090578079224,-5.680666446685791,3.5545711517333984,-1.1451348066329956,-10.41517162322998,1.098379135131836,-3.3872663974761963,-2.1417274475097656,-10.690531730651855,-6.164451599121094,-8.129937171936035,-3.979825258255005,-3.7128918170928955,2.8238608837127686,-4.249817848205566,1.6486369371414185,3.565012216567993,-10.044034957885742,6.0176100730896,-2.87257719039917,-9.260050773620605,-11.620379447937012,-5.652868747711182,-0.7611750960350037,0.8127297163009644,-2.5386409759521484,7.416808605194092,5.374032020568848,-3.4354538917541504,9.97441577911377,-6.523809432983398,-5.902535915374756,0.4472716152667999,4.841671943664551,-1.2006709575653076,5.794190883636475,2.414052724838257,-0.7757186889648438,0.3747713565826416,-2.5331408977508545,1.3378381729125977,-5.168073654174805,-4.892603874206543,-4.403335094451904,1.7585431337356567,2.4437458515167236,-5.732561111450195,-3.427908182144165,3.075519561767578,1.6557745933532715,-2.473137855529785,-3.1445822715759277,-8.623671531677246,-7.716543674468994,-10.766587257385254,-5.738681316375732,-2.460461139678955],"y":[-3.7258877754211426,1.1046783924102783,-5.503127098083496,1.8141660690307617,6.004978179931641,7.812684059143066,-3.06538462638855,-0.9470503330230713,1.7487471103668213,-4.4350361824035645,3.0625784397125244,-2.3039979934692383,1.0910383462905884,-9.821460723876953,-3.1426098346710205,4.354836463928223,6.511940956115723,-0.4056713283061981,-0.3746598958969116,-7.049715995788574,-2.1246514320373535,-4.706948280334473,0.9126614928245544,3.695664882659912,-6.618279457092285,0.0784197598695755,-13.067524909973145,3.189518928527832,7.328683376312256,1.4118826389312744,-3.283846139907837,0.41117018461227417,-1.4838002920150757,-10.271306037902832,-5.1495771408081055,4.485466957092285,-3.1353037357330322,3.6837196350097656,7.85247802734375,-4.783215522766113,5.721037864685059,4.822403430938721,-4.135958194732666,-0.4890314042568207,-1.3202557563781738,2.408480644226074,0.7621860504150391,2.0018467903137207,3.3390090465545654,-8.563116073608398,-10.226465225219727,-1.191735863685608,7.242830753326416,-3.034099578857422,0.03322842717170715,7.7726240158081055,1.24835205078125,-0.222728431224823,-6.665293216705322,8.164008140563965,3.6303927898406982,-0.4792470335960388,2.966247320175171,-4.361012935638428,-0.2506754398345947,0.7891196608543396,3.0138747692108154,6.90535831451416,1.7181205749511719,7.326307773590088,-2.2912604808807373,-7.4594902992248535,-5.0266337394714355,-1.7927029132843018,6.342935562133789,4.430108070373535,-0.12400005012750626,6.629010200500488,2.249016284942627,-2.5752623081207275,12.372475624084473,7.4507646560668945,-0.8368502855300903,7.760642051696777,0.19780531525611877,3.6766979694366455,10.248579025268555,0.648277997970581,-1.9332889318466187,6.860097885131836,-3.7844111919403076,2.679155111312866,0.39525115489959717,-0.4227291941642761,5.142844200134277,1.9690825939178467,-8.030909538269043,2.664194107055664,-4.711690902709961,-6.485541343688965,-2.6211893558502197,-4.53904390335083,-2.3018088340759277,11.051326751708984,-2.249152183532715,-6.848953723907471,-5.570826053619385,-3.6353423595428467,0.7716472148895264,6.256643295288086,1.7876508235931396,-0.6308373212814331,-3.0432069301605225,-5.820298194885254,-8.030435562133789,-11.017093658447266,-4.663051605224609,3.0923311710357666,2.1925201416015625,-0.9559907913208008,6.012911319732666,-0.9069462418556213,-3.859555721282959,3.005328416824341,-1.5160105228424072,0.09417379647493362,1.3777121305465698,-7.38261079788208,-0.3564125895500183,4.996275424957275,9.846251487731934,2.2079029083251953,-4.9951629638671875,1.4687819480895996,-3.8341803550720215,1.924028754234314,-2.5228371620178223,3.2748444080352783,-7.85180139541626,-4.063068389892578,7.289123058319092,-1.9556478261947632,-0.9280635118484497,10.766977310180664],"z":[1.9434248208999634,1.840062141418457,1.8348149061203003,-1.7060896158218384,-4.507420063018799,-2.3002450466156006,-3.3507120609283447,2.1552488803863525,0.6539517641067505,-6.536908149719238,-1.208188533782959,-0.16549503803253174,-2.3260490894317627,-3.719803810119629,-1.4749789237976074,-4.297602653503418,-1.915278434753418,-1.246820092201233,-0.28675493597984314,-7.849104881286621,6.318011283874512,-3.6362099647521973,-0.0901685357093811,-0.7898465394973755,-7.428004264831543,-2.4067540168762207,3.927931785583496,0.09947149455547333,-2.7901828289031982,-3.2397091388702393,1.408532977104187,-1.4779398441314697,3.4293172359466553,1.275644302368164,-2.0210161209106445,-3.729013204574585,4.4425482749938965,0.31548064947128296,-3.3994436264038086,4.1988525390625,-2.5931954383850098,3.8879449367523193,2.419658899307251,-5.1724772453308105,4.846768856048584,-6.340090274810791,-3.6227855682373047,1.6708276271820068,0.14970651268959045,1.2977674007415771,3.14548921585083,4.346822738647461,-6.9147138595581055,0.5501355528831482,-5.316401958465576,-4.3060173988342285,-1.7867780923843384,1.1922482252120972,-0.1730353981256485,2.2150278091430664,-2.049933910369873,-3.5302445888519287,-0.18844197690486908,-2.5098490715026855,-3.7199974060058594,-0.04324197769165039,-0.26967179775238037,-4.306946754455566,-3.186042070388794,-0.16401949524879456,0.02016352117061615,2.393317937850952,3.062716484069824,-3.7299997806549072,8.521259307861328,-2.2268781661987305,-12.454710006713867,-6.241931915283203,-11.001060485839844,-3.213350296020508,-5.8568925857543945,-0.6139464378356934,0.08086159825325012,-3.8831589221954346,2.4932382106781006,6.084605693817139,2.45119047164917,0.7148737907409668,-4.813144207000732,-2.246678352355957,0.19968421757221222,-6.425207138061523,-1.9904897212982178,5.205673694610596,0.03902070224285126,-6.092835426330566,0.20351947844028473,5.57060432434082,3.7030584812164307,1.5084640979766846,1.0106685161590576,1.03496253490448,-1.3128602504730225,-0.5126544833183289,3.210081100463867,-3.5079472064971924,-0.7090774774551392,-2.956690788269043,-5.9539337158203125,0.9849376678466797,-5.835014343261719,-1.8535946607589722,3.256165027618408,-3.8461155891418457,4.196646690368652,-3.6709649562835693,4.824015140533447,2.648966073989868,3.9759230613708496,1.0150643587112427,-1.6957076787948608,-2.017587423324585,0.6928536891937256,2.1800103187561035,-2.774808406829834,0.32427462935447693,-2.205087184906006,-0.2746350169181824,-2.6852777004241943,-1.3896582126617432,1.5588594675064087,-4.685120582580566,-1.2309423685073853,0.14626821875572205,0.42139267921447754,-6.918286323547363,2.784148931503296,-1.4071470499038696,-7.271047592163086,-7.845186233520508,1.4777194261550903,1.918238639831543,2.193408727645874,1.0275448560714722],"type":"scatter3d"},{"hovertemplate":"color=George W Bush<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"George W Bush","marker":{"color":"#00cc96","symbol":"circle"},"mode":"markers","name":"George W Bush","scene":"scene","showlegend":true,"x":[-4.759041786193848,7.312714576721191,1.868348479270935,8.479543685913086,-6.301347255706787,8.390159606933594,1.771436095237732,-1.1961742639541626,-0.5469096899032593,-9.407212257385254,-1.4346743822097778,-1.6059138774871826,-2.3620171546936035,3.871863842010498,0.978725254535675,-1.8113435506820679,-2.3703198432922363,1.1892198324203491,-12.71996784210205,0.6220306158065796,8.301045417785645,-8.687549591064453,8.193620681762695,1.7821482419967651,0.19057880342006683,-2.807225465774536,-4.928335189819336,-4.012378692626953,7.9863505363464355,4.519639492034912,1.6341872215270996,-2.237771511077881,0.07706761360168457,-7.830193996429443,6.807202339172363,1.6137579679489136,0.0931863933801651,8.151071548461914,-4.415097713470459,2.574925422668457,-1.4347364902496338,-4.617445468902588,-8.864970207214355,-2.964167594909668,-0.15486297011375427,-1.4735795259475708,6.1512017250061035,3.5471553802490234,0.19899164140224457,-4.598371982574463,-2.5131661891937256,-1.2409179210662842,-12.106719970703125,-0.14289416372776031,9.880294799804688,-4.763803482055664,6.5367431640625,7.452512264251709,7.440140724182129,-2.8482589721679688,3.273003101348877,2.824864387512207,-5.531435966491699,-14.120779991149902,-4.3415374755859375,0.9006309509277344,-4.628832817077637,0.5450304746627808,10.04515266418457,-2.683915138244629,-5.242672443389893,-5.861991882324219,4.642593860626221,3.288635730743408,-0.6567357778549194,1.593052625656128,-0.39238497614860535,-3.907547950744629,-6.742208003997803,-4.3815460205078125,-0.26195019483566284,-6.955131530761719,1.8854942321777344,-9.061482429504395,0.8454136848449707,6.848270893096924,-6.486680507659912,3.510939359664917,-3.10066294670105,-10.158638000488281,-9.674976348876953,-2.883908748626709,-7.659549236297607,0.4099743366241455,1.0975924730300903,-5.46004056930542,8.027847290039062,3.4151594638824463,-0.73810875415802,-3.5453004837036133,0.45010197162628174,0.1613583117723465,2.232447624206543,-4.165727138519287,-7.016033172607422,-3.6361067295074463,-2.7558956146240234,2.7611899375915527,6.19428825378418,2.401779890060425,8.93322467803955,3.6110823154449463,0.7615233659744263,10.329222679138184,-0.8532029390335083,1.262532353401184,-4.443967819213867,0.6655374765396118,0.21578039228916168,-12.164690971374512,3.5893826484680176,-1.691301703453064,-2.0147767066955566,-3.5246567726135254,-2.98653244972229,-2.2625808715820312,-9.101521492004395,-3.1290793418884277,-0.1252792775630951,10.766844749450684,2.7816262245178223,8.516724586486816,1.7068142890930176,6.410157680511475,-3.920029878616333,-3.771042585372925,3.805384874343872,4.753098487854004,-1.3962594270706177,-2.7774884700775146,-5.419987678527832,-5.361096382141113,-7.295037746429443,4.024596691131592,7.569275379180908,-10.49973201751709,-1.4295955896377563,-5.1455078125,1.7370414733886719,-3.3838589191436768,-10.097980499267578,6.537869453430176,-1.2332154512405396,-5.261626243591309,3.489457607269287,0.4884069263935089,3.8820056915283203,-4.1354169845581055,-3.0620503425598145,-4.765132904052734,5.889821529388428,10.92987060546875,3.70977783203125,6.648292541503906,-5.095589637756348,7.971365451812744,1.8525352478027344,-4.622991561889648,-0.9533811211585999,-5.491574764251709,0.05381707847118378,3.5131044387817383,-1.9587106704711914,-1.3797446489334106,-8.723891258239746,-9.799955368041992,-3.4221811294555664,2.027404308319092,6.095808029174805,8.432106018066406,-0.411385178565979,-16.593421936035156,-1.2241262197494507,-5.456935405731201,-6.1616644859313965,-7.173159122467041,-2.5034849643707275,3.439420700073242,-3.3066189289093018,-4.470631122589111,-9.485163688659668,3.375133752822876,-6.587749004364014,-4.827600479125977,2.2522151470184326,0.12825171649456024,0.10669461637735367,0.07965618371963501,-11.599782943725586,8.417454719543457,4.080870151519775,-8.388718605041504,-1.5401248931884766,6.3481669425964355,-6.9528937339782715,-1.8369145393371582,5.610724449157715,-5.4875617027282715,-7.548183917999268,-1.0513163805007935,-3.1200597286224365,-1.3093961477279663,-6.798210620880127,6.698863983154297,0.4061732590198517,-0.7865493893623352,-2.575314521789551,4.460918426513672,-4.450322151184082,-3.905583381652832,-7.947966575622559,-0.19262874126434326,-10.111652374267578,-3.9357566833496094,4.374422073364258,0.5163884162902832,-5.317967414855957,0.2289700210094452,4.844454765319824,-2.1112539768218994,-3.159902572631836,2.4770658016204834,-3.829089641571045,3.0311496257781982,14.955887794494629,-5.067739963531494,-0.04569023847579956,-7.137659549713135,2.357990026473999,4.138206481933594,5.751440048217773,-7.816156387329102,-1.3425559997558594,0.45982831716537476,4.122981071472168,-5.774146556854248,0.7384048104286194,-7.437072277069092,-1.0117275714874268,-1.446941614151001,0.11920543015003204,7.68007755279541,-5.262523174285889,5.787110328674316,4.745099067687988,6.806838512420654,8.417502403259277,-2.483417510986328,-1.3045036792755127,4.557741165161133,-3.202065944671631,15.180509567260742,-12.838953018188477,15.139592170715332,6.233095645904541,7.586783409118652,-2.2961196899414062,0.9934124946594238,11.197322845458984,1.3179261684417725,2.3527615070343018,3.468038558959961,-7.293777942657471,2.9028890132904053,-4.234649181365967,-1.3601891994476318,3.855376720428467,3.59482479095459,3.925408124923706,0.13744163513183594,-3.178976535797119,-12.149827003479004,3.1137897968292236,1.1151851415634155,-1.1616508960723877,2.9371581077575684,3.623326539993286,-2.928532600402832,2.9940860271453857,-6.157761573791504,-5.954519271850586,-7.430111408233643,11.712381362915039,1.793855905532837,-3.071587085723877,-4.87054443359375,4.609300136566162,-6.870970726013184,-1.2958755493164062,5.9724650382995605,2.2465660572052,3.993698835372925,0.4975002110004425,-2.0364561080932617,3.1350035667419434,-0.8277998566627502,8.394181251525879,2.1340408325195312,-8.625570297241211,0.018831461668014526,-3.8411364555358887,0.3360915780067444,-4.29154109954834,-13.551021575927734,-6.590969085693359,1.9182568788528442,-1.9375758171081543,-1.3779973983764648,-8.94019603729248,-10.6121826171875,-4.356173038482666,17.25307273864746,8.413982391357422,-4.203608989715576,-7.257484436035156,0.08186706900596619,1.0023698806762695,-8.345282554626465,-8.243412017822266,0.46846872568130493,4.306931495666504,-1.4516267776489258,-7.196626663208008,3.419461727142334,-3.115032434463501,5.7152557373046875,-4.957868576049805,-12.898737907409668,-3.691105604171753,3.402035713195801,0.3148691952228546,13.408775329589844,12.295390129089355,1.3443281650543213,-7.182840347290039,4.267317771911621,4.78043270111084,4.375006198883057,3.9145870208740234,-0.7556164264678955,-2.396307945251465,2.127825975418091,-2.795602560043335,3.8307430744171143,-2.7806038856506348,15.740673065185547,-9.748663902282715,5.914322376251221,2.5286757946014404,-4.799155235290527,-3.823256254196167,-0.46441954374313354,8.457145690917969,3.835294246673584,-1.6276930570602417,-4.19766092300415,1.3761228322982788,-7.983733654022217,-0.5515239834785461,0.42452114820480347,3.0806832313537598,4.434153079986572,-0.6677626371383667,1.868523120880127,-1.0475434064865112,-4.166067123413086,15.126297950744629,-6.168648719787598,1.2525824308395386,-4.167900085449219,-1.5818992853164673,-4.391097545623779,-15.170215606689453,-4.796937465667725,-0.20211341977119446,3.69779634475708,-9.722946166992188,-1.4227619171142578,-10.284178733825684,0.6958346366882324,-5.766453266143799,2.8143041133880615,-0.004878997802734375,-4.709046363830566,0.130070298910141,-4.425072193145752,-0.928642749786377,-4.0306267738342285,11.693170547485352,6.693499565124512,-7.027186393737793,0.5522320866584778,-2.8849778175354004,3.0456180572509766,-1.7550698518753052,-3.0626795291900635,-8.967546463012695,2.4144444465637207,0.8888601660728455,-4.188485145568848,-3.580793857574463,-2.652015447616577,-8.49515151977539,-2.633620023727417,10.115757942199707,-8.431748390197754,4.247318267822266,1.7920236587524414,-4.999651908874512,0.868118941783905,4.635915756225586,-7.012867450714111,0.6628356575965881,5.431979179382324,-1.9101771116256714,4.656611919403076,-9.735681533813477,0.5801422595977783,-1.7360546588897705,-1.2972387075424194,-0.4146854281425476,-2.900653123855591,3.709895610809326,-1.6166715621948242,0.6588337421417236,-1.6696703433990479,2.30204701423645,-2.0279815196990967,1.4475091695785522,10.381070137023926,-4.841504096984863,3.5102155208587646,-5.430158615112305,-8.615398406982422,-2.5051934719085693,6.12453556060791,-2.1912007331848145,1.822283387184143,0.8974862098693848,-3.0950586795806885,-5.383180141448975,5.39207649230957,-4.715838432312012,6.454550266265869,-0.7135026454925537,6.60849142074585,4.459745407104492,-8.459389686584473,-8.019079208374023,-3.1039488315582275,1.4302680492401123,3.9305579662323,3.031898260116577,-3.163662910461426,-7.393126964569092,19.422693252563477,-4.42133092880249,5.818310260772705,-13.586421012878418,-0.3287493586540222,4.996823787689209,7.6960930824279785,-2.343059539794922,-6.365478992462158,0.5582241415977478,9.537789344787598,-10.147271156311035,1.2264049053192139,5.78363561630249,-6.287137985229492,6.224334239959717,0.41317370533943176,-1.493906855583191,-0.008622545748949051,3.221186399459839,-5.935110092163086,-4.007080078125,6.3073625564575195,4.5611491203308105,4.451038837432861,-1.2643970251083374,-7.565555095672607,-2.733002185821533,0.8419044017791748,-10.364794731140137,9.364832878112793,1.5309388637542725,-2.2540361881256104,0.87477046251297,0.17371366918087006,-8.293237686157227,2.8678886890411377,5.193967819213867,-1.311484456062317,13.555512428283691,-6.5527167320251465,-2.8948469161987305,8.038344383239746,-3.056652307510376,-3.2969970703125,-1.5188941955566406,-0.1629095822572708,-2.034477472305298,12.9147367477417,1.0032135248184204,-3.11146879196167,5.348800182342529,-6.343820571899414,0.3180428743362427,-0.6993774175643921,2.0378239154815674,-3.155667304992676,-5.7833099365234375,8.814099311828613,1.9444729089736938,-1.7267178297042847,-5.445565223693848,-11.692085266113281,4.668919563293457,-7.4053168296813965],"y":[-1.6256420612335205,-0.004204899072647095,-11.636563301086426,2.6009886264801025,-4.987905025482178,10.78207015991211,10.436844825744629,-6.14678430557251,0.9443473815917969,-0.2164911925792694,-1.7950764894485474,-1.041664719581604,3.0398569107055664,-7.580151081085205,2.406371831893921,-5.906740188598633,-0.9178895950317383,-4.787419319152832,-7.8597025871276855,-2.1513800621032715,6.377419471740723,3.5134224891662598,-0.7308452129364014,-10.573028564453125,1.709704875946045,-0.16040068864822388,-1.4825751781463623,0.5029525756835938,-3.6411664485931396,2.1157994270324707,1.3081015348434448,3.3238070011138916,0.18173256516456604,0.9182413220405579,-1.5455772876739502,-1.4727109670639038,-10.994013786315918,-3.656254768371582,-0.32421958446502686,1.19442880153656,2.0992324352264404,9.21545696258545,-3.251106023788452,1.9406602382659912,-3.4771828651428223,-2.1068220138549805,1.6803865432739258,3.7298896312713623,3.6406009197235107,-3.377591133117676,0.6568178534507751,1.3736436367034912,7.021627426147461,-2.8237733840942383,6.621508598327637,-2.560506582260132,0.7728270292282104,1.657023549079895,4.710575103759766,7.15991735458374,-2.4250118732452393,11.612258911132812,3.1441047191619873,-4.584217071533203,0.7455578446388245,-4.208581924438477,0.0036618411540985107,5.572011947631836,3.2243740558624268,6.20908784866333,-7.968635559082031,5.608529567718506,-3.228006362915039,-9.877573013305664,-4.055301189422607,-9.088425636291504,-8.178586959838867,0.7098721265792847,-1.6938682794570923,-0.29286596179008484,-4.3064866065979,4.399963855743408,8.721280097961426,-7.336167335510254,-1.8653855323791504,0.04384660720825195,12.87117862701416,1.7200077772140503,-6.745016098022461,-5.960485935211182,1.0728037357330322,2.669241189956665,6.6190643310546875,-1.1495118141174316,-5.852871417999268,-1.9609675407409668,-1.700559377670288,-15.159220695495605,4.881259441375732,4.644186496734619,1.0548518896102905,-2.338838577270508,-5.843832015991211,-4.021610736846924,4.732039928436279,0.15731339156627655,-1.4460361003875732,7.962326526641846,-4.688711166381836,-3.2974586486816406,6.881723403930664,-2.5624754428863525,5.414912223815918,-3.354793071746826,-1.1236112117767334,-2.2057838439941406,0.49218228459358215,-8.742308616638184,-2.021301507949829,4.913229465484619,-4.030588626861572,-2.467538356781006,-4.611827850341797,10.927839279174805,-4.532761096954346,11.529199600219727,2.9887535572052,-3.689112663269043,0.7128557562828064,3.922691583633423,2.8594086170196533,2.0522985458374023,11.559191703796387,-2.312767744064331,2.6619420051574707,1.5420000553131104,2.4210445880889893,4.594283580780029,-9.521323204040527,-0.610382616519928,-0.6152190566062927,2.801455497741699,-6.4164910316467285,1.3925130367279053,-4.95438289642334,2.1318423748016357,1.8571807146072388,5.686498165130615,6.080132007598877,-1.9693241119384766,-2.145860195159912,-0.16377854347229004,2.873262643814087,-2.7924044132232666,-0.20712868869304657,3.3433268070220947,-7.669216156005859,-9.749051094055176,1.5911914110183716,1.674210786819458,4.862832069396973,5.651394844055176,4.175332069396973,0.4276546835899353,5.80312967300415,-12.824936866760254,-3.3545196056365967,0.03535503149032593,-5.640835762023926,6.003807067871094,1.6315115690231323,-0.5546315312385559,-3.168903350830078,11.48733901977539,0.6273782849311829,3.95243763923645,-1.7424495220184326,-1.1613621711730957,0.80726158618927,7.680474758148193,4.100777626037598,-5.349384307861328,6.701807975769043,-0.202201709151268,-7.325551509857178,5.9025983810424805,-1.255798101425171,6.055919647216797,7.961409568786621,7.126745223999023,8.678332328796387,-2.2117762565612793,-3.795553207397461,9.722939491271973,-0.8153563737869263,6.295273303985596,-1.6904079914093018,5.059476852416992,-3.8353400230407715,-2.632239818572998,-2.934391975402832,-1.1833702325820923,-3.716736316680908,-6.017749309539795,-1.9928995370864868,0.17351405322551727,-1.7489463090896606,0.5763211250305176,-2.3051512241363525,-9.488112449645996,1.6904667615890503,-6.266764163970947,-12.942703247070312,3.287416696548462,-5.559950828552246,-7.1510138511657715,6.104937553405762,-1.4338057041168213,-0.6556693315505981,-2.687304973602295,-3.3637871742248535,-4.151172161102295,1.366355538368225,3.0738892555236816,3.0943806171417236,-1.9623472690582275,1.2510526180267334,-7.554036617279053,1.964371681213379,1.6196556091308594,-1.0522948503494263,-2.552046060562134,-5.218122959136963,-5.086673736572266,2.2084031105041504,-2.3610527515411377,3.7969865798950195,-5.488185405731201,-6.401742458343506,3.53548526763916,-9.887630462646484,-0.3712165355682373,-7.824769020080566,5.890805244445801,5.618227005004883,12.982146263122559,-4.7512617111206055,-1.3662220239639282,6.928077697753906,3.5884196758270264,5.179696083068848,-3.5545969009399414,2.1639397144317627,4.293392658233643,15.594799041748047,-2.1002731323242188,2.4370226860046387,-6.3648481369018555,-2.1008665561676025,5.457380294799805,0.8892049789428711,2.776392698287964,-7.539083480834961,-11.643682479858398,-3.377023935317993,-2.106433391571045,5.9170074462890625,2.289415121078491,-9.226356506347656,1.9422593116760254,8.486560821533203,1.020684003829956,6.605271816253662,3.9995498657226562,-1.5921809673309326,7.073523044586182,1.0949726104736328,-4.436077117919922,-0.16134363412857056,0.7938700914382935,0.5140640139579773,2.860495090484619,-1.5536640882492065,9.584372520446777,-3.6874947547912598,-3.024071216583252,-2.2236199378967285,0.4771130084991455,7.921048164367676,2.5505919456481934,-2.0510940551757812,1.4224271774291992,5.034069061279297,-4.223576068878174,5.650052547454834,-7.925834655761719,8.521480560302734,0.08818376064300537,18.21297264099121,1.3024606704711914,-5.198063373565674,4.557199001312256,1.731867790222168,8.032520294189453,-8.259801864624023,-0.6866402626037598,-2.584493637084961,3.54730486869812,-3.1358046531677246,-1.008948564529419,-3.01997971534729,2.413637399673462,-0.4314357340335846,0.4913688898086548,7.4123029708862305,-4.376498699188232,8.565058708190918,-5.4346232414245605,-0.38796430826187134,0.30388590693473816,-10.384007453918457,-5.929630756378174,-12.052044868469238,-8.924477577209473,3.5420613288879395,1.7987208366394043,1.0555564165115356,-1.8627516031265259,-1.9863516092300415,12.835834503173828,3.4350757598876953,1.569275975227356,5.144649982452393,1.4471683502197266,-3.1709299087524414,0.2502707242965698,5.047108173370361,9.32502269744873,13.544090270996094,-3.653963804244995,4.8585333824157715,-4.010871887207031,-7.579849720001221,1.5549004077911377,2.589329242706299,-5.8798346519470215,-0.8009226322174072,-5.4208855628967285,-0.12814800441265106,0.1610438972711563,-7.824971675872803,-2.7139549255371094,6.055213928222656,-0.06870639324188232,5.769137859344482,3.5643696784973145,8.387401580810547,-5.132237434387207,-3.378504753112793,1.4767199754714966,-0.7642850875854492,-7.757025718688965,1.7475570440292358,-1.7158818244934082,-0.48838773369789124,7.5743327140808105,-0.3073207437992096,1.6465219259262085,-5.9836649894714355,1.5903398990631104,9.321698188781738,-1.6886224746704102,-4.771884918212891,-5.880616188049316,7.935424327850342,-0.4215911626815796,-3.4693267345428467,-7.0803914070129395,8.206635475158691,6.672440528869629,-1.437575340270996,2.8746626377105713,-1.5959289073944092,7.147753715515137,0.06598341464996338,-4.666691303253174,-0.9384223818778992,2.1659138202667236,3.4073522090911865,8.073026657104492,-4.565826892852783,-7.611240863800049,8.451309204101562,2.9924044609069824,8.47826099395752,5.656740665435791,-3.750566005706787,-0.7015788555145264,-11.674930572509766,4.788933753967285,2.3047170639038086,-0.26993727684020996,-2.906447410583496,1.7967965602874756,2.708937406539917,14.38235855102539,-4.005648612976074,-10.549434661865234,-2.101839542388916,-0.8684064149856567,-1.991688847541809,-6.8880414962768555,-2.997213363647461,0.2965388596057892,-0.05776527523994446,-3.494658946990967,4.193435192108154,-0.5875570774078369,-2.780989170074463,-3.375898838043213,-14.241567611694336,-2.1306145191192627,0.9450060129165649,4.9784393310546875,-4.400866508483887,-0.973615825176239,1.4418385028839111,-3.153632879257202,-6.345046520233154,4.4436750411987305,8.283720970153809,-2.26025652885437,-3.6406660079956055,2.550905704498291,-3.087520122528076,3.9842400550842285,2.22113299369812,-11.7278413772583,6.017854690551758,-2.005427598953247,6.08145809173584,4.406616687774658,3.4086055755615234,-5.405259609222412,3.113441228866577,2.737867832183838,-6.490993022918701,-6.22166109085083,4.2231125831604,-3.266763210296631,0.04884031414985657,-4.614835739135742,0.5894423723220825,-4.222701549530029,-6.901588439941406,7.089288711547852,5.6777119636535645,-9.085675239562988,-5.048769474029541,-1.906497597694397,-0.11456620693206787,-7.079649925231934,3.54099440574646,0.7091457843780518,0.3266752362251282,-2.257383346557617,7.349575042724609,-1.652515172958374,-2.829763889312744,-1.0693554878234863,2.8787665367126465,8.426265716552734,-2.3078830242156982,-0.19347506761550903,-1.3809758424758911,5.240213394165039,1.8905028104782104,-3.3125061988830566,-3.3359761238098145,11.437634468078613,-7.793026924133301,-6.388422012329102,4.8540544509887695,3.037595748901367,-1.5072009563446045,-5.993690490722656,0.11097261309623718,-4.651857852935791,-1.8012077808380127,-5.139663219451904,0.48645442724227905,-8.419425964355469,7.1951751708984375,4.046141624450684,6.993456840515137,-2.8640854358673096,3.6597602367401123,8.5127592086792,2.13971209526062,2.9490890502929688,1.822920560836792,-3.0864782333374023,0.20836521685123444,-7.451458930969238,1.067902684211731,-2.8641295433044434,-2.580775022506714,-0.6626573801040649,0.7763148546218872,-1.6338800191879272,2.3708488941192627,7.576218605041504,-2.500216007232666,1.22385573387146,4.452915668487549,-2.7112789154052734,0.03450050204992294,2.8379220962524414,0.1477663218975067,8.882111549377441,-0.06836859881877899,-3.2513060569763184,-2.620861530303955,-5.6977033615112305,3.3248674869537354,-1.4051392078399658,11.084057807922363,-3.5371665954589844,3.6372435092926025,-3.3329896926879883],"z":[-2.656641960144043,4.426687240600586,-2.034651517868042,0.4800316095352173,4.480134963989258,-3.5890538692474365,1.667853832244873,4.660483360290527,-1.5505977869033813,-0.17096060514450073,6.116481304168701,3.0550146102905273,4.89494514465332,4.654152870178223,0.6783584356307983,-4.907393455505371,2.7267775535583496,-0.5764936208724976,-5.80842399597168,-6.368191242218018,1.0550758838653564,-4.656020164489746,0.5585905313491821,-2.9715030193328857,-4.692381858825684,2.6215031147003174,1.9241292476654053,6.30498743057251,0.4633851647377014,-1.6338250637054443,9.079392433166504,2.203420400619507,-3.188488006591797,-0.5754302144050598,-3.173919200897217,4.526832103729248,-4.308539867401123,5.64565372467041,-0.7663512825965881,-0.3171619474887848,-1.704298734664917,-1.6003797054290771,0.36025673151016235,0.3816675543785095,6.6141743659973145,4.170086860656738,-7.035390853881836,-0.018379628658294678,-0.357909619808197,-2.6441383361816406,6.148423194885254,0.9407998323440552,-1.6095731258392334,-0.5428077578544617,0.17331314086914062,5.050260066986084,0.10800760984420776,1.2749465703964233,0.575498640537262,2.5192973613739014,-3.0590744018554688,-4.926366329193115,-1.6124153137207031,3.3644096851348877,3.01133131980896,3.068298101425171,1.9916678667068481,0.70054030418396,5.6185622215271,0.37624746561050415,0.8848628997802734,5.99064302444458,0.38572126626968384,-5.717274188995361,-2.908304452896118,-3.5482375621795654,-4.98802375793457,-1.173292636871338,-2.2202346324920654,7.203347206115723,-1.745399832725525,-2.116644859313965,4.28645133972168,6.514057636260986,-4.935927867889404,2.2835283279418945,-2.51985239982605,3.6414570808410645,-0.9025291800498962,-0.07876543700695038,-3.1556143760681152,2.223252058029175,-3.546598434448242,-1.2903367280960083,-2.656257390975952,-1.9174349308013916,-8.683758735656738,-0.6276987791061401,4.224844455718994,1.2835265398025513,3.047333240509033,1.1030137538909912,1.2376667261123657,0.2310246229171753,4.769970417022705,-2.781252145767212,-1.465487003326416,1.4564330577850342,-2.212841510772705,-2.0942273139953613,0.6832031607627869,3.3241219520568848,-1.8927780389785767,1.2205018997192383,2.2905542850494385,3.3110036849975586,1.8949685096740723,-10.090398788452148,-2.5187184810638428,4.688918590545654,2.6680569648742676,-0.4752108156681061,3.227825880050659,-2.413597345352173,-1.7618738412857056,-0.004605025053024292,4.477278232574463,4.204742431640625,-2.015617609024048,0.36574167013168335,-2.2913687229156494,-2.9962193965911865,-1.1356021165847778,1.9396042823791504,0.11104223132133484,0.5224907994270325,5.542220592498779,3.7530579566955566,-1.5092065334320068,3.66987943649292,0.06636150181293488,0.6113651394844055,-4.0718231201171875,2.2082691192626953,-0.544955313205719,-0.6841207146644592,-3.019782543182373,2.791572332382202,-3.387331485748291,1.4401068687438965,4.172210693359375,3.256631374359131,3.6097593307495117,-9.908699035644531,-0.14351105690002441,12.85571002960205,-3.852670431137085,0.3313743472099304,0.047745928168296814,2.1466450691223145,-1.8385627269744873,-1.0436809062957764,6.909436225891113,-2.6134138107299805,-1.6809321641921997,-1.7718470096588135,4.92816162109375,-3.768467426300049,4.60702657699585,-6.803895950317383,1.4478931427001953,-5.754787445068359,4.103105545043945,-3.8653054237365723,-3.816357135772705,-5.4538726806640625,0.6263073086738586,1.1783757209777832,2.371554374694824,0.49359026551246643,3.361661911010742,-2.85602068901062,-0.9257363080978394,-2.269026756286621,-5.230369567871094,-1.2424414157867432,3.8989531993865967,3.1053218841552734,-1.9086154699325562,-0.150482177734375,3.4799060821533203,0.6659198999404907,-2.394883155822754,2.3632380962371826,-6.661815643310547,-1.0955005884170532,1.8134362697601318,-3.370250701904297,5.026846408843994,0.3455617129802704,5.649890422821045,-0.127201110124588,-5.472975730895996,5.9743733406066895,-2.532672882080078,3.866832733154297,-2.1626198291778564,-2.9821534156799316,-2.0714163780212402,3.234079122543335,2.8204658031463623,2.033719539642334,0.6678823828697205,6.667367935180664,1.6530911922454834,-0.06535065919160843,0.153191938996315,1.5079362392425537,2.2083771228790283,-0.3772001564502716,1.426946759223938,2.1534109115600586,-1.6856368780136108,-3.0002191066741943,0.6319363117218018,-2.9339945316314697,5.413830280303955,0.9877488017082214,2.52919340133667,-7.086312294006348,2.169186592102051,-2.098579168319702,4.319887638092041,-4.868015289306641,-1.6385533809661865,5.302898406982422,-1.9857335090637207,3.4627037048339844,-2.5431785583496094,-0.5820060968399048,0.07047820091247559,4.656337261199951,0.38217079639434814,3.537898540496826,-1.0108520984649658,-5.697882175445557,-0.25527462363243103,-1.9678221940994263,1.9920710325241089,-6.842774391174316,-0.06286739557981491,3.759214401245117,-5.550312519073486,-1.3549015522003174,-3.2090141773223877,1.1739612817764282,5.747377872467041,-2.058417320251465,3.181058168411255,-5.367379188537598,0.4086448550224304,5.36024808883667,3.7010130882263184,-1.9130592346191406,3.54312801361084,3.757661819458008,5.687121868133545,-0.1857099086046219,-0.63912433385849,5.937983989715576,5.440377235412598,-1.0429275035858154,2.618149518966675,0.5118155479431152,-0.4516410827636719,8.03669548034668,2.770341396331787,-1.4334030151367188,4.538052082061768,1.839235544204712,3.518556833267212,5.812307357788086,1.7082017660140991,7.567150115966797,2.1931140422821045,-3.3038570880889893,-7.335755825042725,1.2521729469299316,4.401218414306641,0.2648929953575134,3.0048751831054688,-0.14644449949264526,6.756795406341553,0.699771523475647,3.018099308013916,-4.188841819763184,4.6642632484436035,2.15645170211792,-1.0342577695846558,2.126207113265991,-0.07829207181930542,2.142646074295044,2.722740411758423,11.564849853515625,3.261484146118164,-1.1881227493286133,-3.042858362197876,1.6860833168029785,-4.356217861175537,2.756197929382324,2.5859622955322266,-2.5293283462524414,2.697948455810547,-4.5688910484313965,1.2725026607513428,-3.8738088607788086,4.032047271728516,-1.4610108137130737,0.716864287853241,1.1450291872024536,-2.2370221614837646,6.314497947692871,-0.9558848738670349,-2.857858896255493,-1.3558552265167236,3.160071849822998,-0.7082765102386475,-3.6943047046661377,-3.9725022315979004,0.2678822875022888,-6.419750213623047,5.522616863250732,-2.298701047897339,5.294111251831055,-1.0970256328582764,1.7778244018554688,-4.861400127410889,1.4200307130813599,5.81124210357666,3.0668678283691406,7.699252128601074,-5.306186676025391,-8.062026977539062,1.7955371141433716,-5.371623516082764,1.3082621097564697,-0.4298694431781769,-0.3449561893939972,0.8997442722320557,0.4341811537742615,3.3354146480560303,-2.8199496269226074,2.031444549560547,2.2442197799682617,7.800112724304199,-2.5708653926849365,0.8795596361160278,-2.3563151359558105,2.284451961517334,-0.24985498189926147,2.362382173538208,4.712707996368408,-1.5549079179763794,-7.905937194824219,1.5662835836410522,-5.092383861541748,-1.031665563583374,0.8590494990348816,4.444485187530518,0.7124661207199097,-3.113694906234741,1.036546230316162,2.733659029006958,3.4108948707580566,-1.929902195930481,-0.9304537773132324,4.906932830810547,-1.360194444656372,-0.11781233549118042,-1.646891474723816,-3.3284530639648438,1.1141471862792969,-1.3800371885299683,-8.624704360961914,-4.635025978088379,5.155113697052002,-1.7554922103881836,-1.5926499366760254,-0.40367311239242554,-0.45385658740997314,3.150855302810669,-0.4298032522201538,-6.49862813949585,2.174485683441162,-3.9827113151550293,2.977632761001587,-3.0202510356903076,7.05766487121582,-1.6816494464874268,3.7418484687805176,-0.6200652122497559,-1.1206499338150024,-0.6060848832130432,-0.1846485584974289,-2.8228907585144043,-0.4802320599555969,-1.419176697731018,0.01658622920513153,1.3683174848556519,-3.368788003921509,-4.973597049713135,1.8612351417541504,-1.9244933128356934,0.7344688177108765,4.577682018280029,3.4477291107177734,-0.1751512587070465,1.8906495571136475,2.357548713684082,0.7908725738525391,-0.7192613482475281,2.5441198348999023,0.16905497014522552,5.1975603103637695,5.670948028564453,-1.483834981918335,3.373579502105713,0.23830056190490723,-3.3293778896331787,0.7727959156036377,-2.7435173988342285,1.2271873950958252,3.411405324935913,0.21997518837451935,2.1394898891448975,-2.185917854309082,5.899783611297607,-0.22696387767791748,5.535912036895752,-4.729694366455078,1.6598395109176636,0.2431274950504303,4.050228118896484,-4.937578201293945,1.7755976915359497,-2.922285318374634,-2.097055196762085,5.0973591804504395,1.964139461517334,2.256155014038086,-0.6723994612693787,-4.787416458129883,0.7601819038391113,-1.2680668830871582,3.4189727306365967,-5.307217597961426,-1.2859681844711304,3.8125734329223633,-5.3381147384643555,7.118860721588135,0.7113478779792786,-0.06069934368133545,3.423393726348877,1.8367422819137573,3.4579317569732666,-0.04983225464820862,-0.030601203441619873,6.114151954650879,-0.6691295504570007,-3.3489456176757812,6.37184476852417,-3.2844619750976562,-0.24081242084503174,2.1727375984191895,7.351134777069092,-3.767465829849243,-1.564415454864502,1.4459965229034424,-0.011691153049468994,0.11925196647644043,-0.8803903460502625,4.536954879760742,-1.9755942821502686,3.675105333328247,5.909928321838379,3.038421869277954,-2.0785117149353027,-6.279539108276367,0.2807505428791046,4.094900608062744,7.054446220397949,5.029644966125488,2.6252670288085938,-7.010551452636719,5.62180757522583,0.3938250243663788,3.574897050857544,0.31635624170303345,-2.3499104976654053,0.990143895149231,1.9638128280639648,2.7327141761779785,3.363100051879883,-4.480989933013916,-10.408671379089355,0.1425061821937561,-1.7106200456619263,7.0759100914001465,3.112443447113037,2.008394718170166,1.0121959447860718,-0.18357139825820923,-0.04984486103057861,0.8337845802307129,3.8554158210754395,1.8152375221252441,0.468723326921463,-1.1322633028030396,-0.24174131453037262,6.282876014709473,5.6338791847229,1.8712728023529053,2.67051362991333,-6.547845840454102,-0.34082746505737305,2.317202091217041,-3.201059103012085,0.9181120991706848,-4.33345365524292,3.016763925552368],"type":"scatter3d"},{"hovertemplate":"color=Colin Powell<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Colin Powell","marker":{"color":"#ab63fa","symbol":"circle"},"mode":"markers","name":"Colin Powell","scene":"scene","showlegend":true,"x":[1.4915094375610352,4.189841270446777,1.6947828531265259,1.3757675886154175,4.180511951446533,2.2361347675323486,11.461226463317871,-0.3553515672683716,7.492954254150391,1.9994865655899048,5.53771448135376,-2.281597137451172,-1.212334394454956,-3.1700849533081055,-4.777135848999023,-0.24347931146621704,7.853565216064453,-3.8885443210601807,12.149133682250977,11.45553207397461,1.8550925254821777,4.589756011962891,6.156003475189209,-7.846909046173096,4.52825927734375,0.2370796650648117,11.12610912322998,-4.039412975311279,6.897356033325195,5.724722385406494,-4.01024866104126,0.28263720870018005,0.5307801961898804,3.269791603088379,5.956924915313721,15.757149696350098,3.8378350734710693,0.33281680941581726,1.77628755569458,6.629692077636719,-2.353698253631592,-2.613633394241333,0.5942875146865845,11.345958709716797,-2.3955469131469727,3.6440072059631348,-10.813322067260742,6.827456951141357,-9.349823951721191,7.498349666595459,-3.9628005027770996,11.086535453796387,7.645318031311035,7.000107765197754,7.959409236907959,4.859663009643555,3.5274903774261475,3.7748637199401855,-8.122962951660156,3.8067314624786377,8.974756240844727,9.534346580505371,3.329054594039917,5.204987525939941,7.446692943572998,7.441997528076172,-0.31280767917633057,7.823497295379639,-6.197872161865234,-7.749338626861572,5.7171173095703125,-0.4120946526527405,6.349087238311768,4.374103546142578,-2.0237019062042236,0.33058005571365356,7.56410551071167,7.273560523986816,2.819467544555664,-2.5951685905456543,4.117283344268799,9.416204452514648,-3.9875121116638184,12.210233688354492,6.85553503036499,-5.401012897491455,0.7346466183662415,5.908751010894775,-2.447033643722534,-6.476481914520264,1.2086734771728516,-3.3356757164001465,1.3838012218475342,-0.2726689875125885,3.9441640377044678,-3.818842887878418,-11.75373363494873,0.8167107105255127,-0.23469966650009155,4.32490348815918,5.960622310638428,7.091461181640625,13.399884223937988,-9.8477783203125,-4.334473133087158,-6.550064563751221,-1.3611446619033813,2.014239549636841,0.06616359949111938,9.18571662902832,-3.5698328018188477,-2.281036615371704,-9.763504981994629,3.290790557861328,10.49952507019043,-10.371663093566895,-11.856529235839844,0.11491810530424118,3.4257655143737793,2.5983595848083496,-3.919743061065674,-3.1554813385009766,13.026978492736816,13.594060897827148,-9.215513229370117,-0.11113157868385315,-7.093573093414307,2.9301767349243164,-12.024383544921875,4.586374282836914,-1.3434650897979736,-3.943514585494995,12.380627632141113,3.0113189220428467,0.576761782169342,-6.14548921585083,6.269326210021973,7.373180866241455,1.6726711988449097,-0.7210016846656799,3.447528123855591,5.0214738845825195,6.900144577026367,-2.1716268062591553,7.763556003570557,-0.5031659603118896,2.814272880554199,-2.788390636444092,-1.6079434156417847,0.07138382643461227,7.384352207183838,-6.869327545166016,7.209078788757324,-1.6895867586135864,1.2021108865737915,1.9561588764190674,2.7725696563720703,6.6595845222473145,-3.62211275100708,11.387072563171387,-0.15561740100383759,9.916226387023926,7.730597019195557,11.449999809265137,7.8066606521606445,0.6840946078300476,0.3377552926540375,1.479862928390503,4.896602153778076,-3.212695837020874,3.981210231781006,0.41129258275032043,4.575814723968506,7.502694606781006,5.10015869140625,-7.3023152351379395,-11.400327682495117,3.8331573009490967,0.8713119029998779,-5.514593124389648,-1.9977779388427734,2.018311023712158,-1.1778771877288818,0.543599009513855,2.462193250656128,-0.8361252546310425,3.481171131134033,9.018319129943848,2.330495834350586,2.882629156112671,7.708569526672363,-2.281270742416382,-1.6988003253936768,0.9423205852508545,-1.9846692085266113,-5.814384460449219,-2.6139142513275146,3.668850898742676,-1.5876785516738892,9.898913383483887,5.7110748291015625,0.8620027899742126,-6.460963726043701,1.8085485696792603,0.3470528721809387,-0.15713509917259216,1.8166853189468384,5.642560958862305,9.902727127075195,-0.8408446311950684,-11.714293479919434,-8.54621696472168,-2.720724582672119,4.656734943389893,-4.603704452514648,-4.897441864013672,4.681272506713867,1.68885338306427,4.372844696044922,1.4863810539245605,-1.081774353981018,0.9757993817329407,6.045135498046875,4.302562236785889,4.877799034118652,-0.23086847364902496,2.54884934425354,0.7801282405853271,7.151650428771973,-4.6338911056518555,-3.5876455307006836,5.112168312072754,2.2825138568878174,7.711415767669678,-1.074859380722046,2.6651206016540527],"y":[-1.6209888458251953,-7.033556938171387,-4.589630603790283,0.1796589493751526,1.0724304914474487,1.5778645277023315,4.751982688903809,-9.167777061462402,2.6600639820098877,-4.811407089233398,-8.433799743652344,-5.216200351715088,-4.20676326751709,-4.460139751434326,-9.081443786621094,2.4908347129821777,-0.5581943988800049,3.6511402130126953,1.773761510848999,-0.13630680739879608,5.372734069824219,-3.7513139247894287,4.133047103881836,5.263617038726807,-2.3007636070251465,3.316361427307129,-8.53641414642334,-4.023690223693848,-1.6506353616714478,6.673452377319336,0.823934018611908,-2.6279542446136475,-7.187860488891602,-3.1474452018737793,5.109927654266357,-4.948592185974121,-2.978161096572876,-1.3844987154006958,1.9233977794647217,0.6314502954483032,0.007320016622543335,-2.5887739658355713,-7.085544109344482,-6.991143226623535,-3.8697657585144043,-0.7031099796295166,-0.16714301705360413,4.0515947341918945,-3.0521326065063477,3.8647453784942627,1.8404209613800049,9.404502868652344,-5.123711109161377,-0.5008708238601685,3.3470683097839355,-1.4537203311920166,1.9528359174728394,-3.9905450344085693,-3.393950939178467,-6.4246721267700195,0.431188702583313,2.8186862468719482,-0.4274556338787079,0.1500382423400879,-1.487430214881897,-4.225779056549072,0.7903852462768555,-11.39825439453125,-7.897376537322998,0.5605072975158691,2.1647982597351074,-1.8632022142410278,-3.597168207168579,1.3801037073135376,7.512780666351318,-0.1277754157781601,0.42122218012809753,-2.575035810470581,-4.72776460647583,2.182870864868164,4.149878978729248,4.19618034362793,-4.038847923278809,-1.0100046396255493,0.2659846544265747,9.501496315002441,3.631002187728882,-3.488920211791992,1.9090656042099,6.202169895172119,-7.976869583129883,-0.9030872583389282,-2.4772534370422363,-3.8730790615081787,2.7135210037231445,-1.1579394340515137,-4.4663286209106445,-2.4848413467407227,-0.17958272993564606,0.5046868920326233,0.9683828353881836,1.305049180984497,2.8425235748291016,6.970872402191162,3.52077317237854,-3.243562936782837,-0.9059937596321106,10.953044891357422,-1.2144436836242676,0.7005939483642578,6.796423435211182,19.21169090270996,4.906687259674072,-0.20232968032360077,-3.249884843826294,-7.350943565368652,5.811422348022461,-2.6571543216705322,6.4777936935424805,4.167636394500732,1.600826621055603,4.187767028808594,-3.101088047027588,2.011810064315796,-9.311338424682617,-6.048985004425049,-6.046621799468994,-4.32113790512085,-8.034017562866211,-0.3754243552684784,-3.471256971359253,2.664618968963623,3.4554333686828613,2.7292144298553467,8.844542503356934,-4.236725807189941,-4.061649322509766,-4.058629989624023,15.443805694580078,0.10779765248298645,4.67345666885376,-4.514224529266357,4.244533538818359,-0.6606330871582031,-5.131180286407471,3.9480912685394287,-1.1540734767913818,3.0106823444366455,-1.2627489566802979,-3.832218647003174,-0.731255054473877,-4.471132278442383,-2.0706777572631836,-5.594851970672607,5.008893013000488,2.155428409576416,1.7913813591003418,-1.033084750175476,-2.7375752925872803,-0.570477306842804,-3.624039649963379,-0.033728837966918945,6.749969959259033,11.187376022338867,-2.8563034534454346,-4.7350382804870605,-3.409949779510498,-0.13166497647762299,-1.047865629196167,9.067042350769043,-3.3655216693878174,0.24097010493278503,-0.08147113025188446,-5.572652339935303,6.08301305770874,-2.840679168701172,-2.8033900260925293,-1.1875004768371582,-3.90313458442688,6.038904666900635,1.951991081237793,0.3325232267379761,-4.84298849105835,0.9222347140312195,-4.6650071144104,2.7625715732574463,-7.913590431213379,-5.824667930603027,0.30197417736053467,-0.406650185585022,0.742755115032196,1.9815545082092285,2.588916063308716,0.4991329610347748,-1.8140990734100342,1.671147346496582,-0.9205998778343201,0.13605010509490967,9.929425239562988,-1.464993953704834,-2.694450616836548,8.767319679260254,0.0007225573062896729,2.1619884967803955,3.842602491378784,0.7245004773139954,5.143449306488037,4.348437309265137,4.399716377258301,-3.0715084075927734,-2.6160905361175537,-5.647671699523926,-3.360719680786133,3.9005517959594727,-2.9645936489105225,-8.906219482421875,-2.124213695526123,-4.341805458068848,9.145015716552734,0.2758353352546692,0.5069957971572876,0.9481943249702454,3.009500026702881,3.4589643478393555,-0.22846999764442444,4.989652633666992,6.92295503616333,3.9899611473083496,3.6873550415039062,-7.016189098358154,-3.3442375659942627,5.070841312408447,-3.951552391052246,-1.7325950860977173,3.993582010269165,-0.37674081325531006],"z":[2.5627541542053223,-3.692641019821167,0.5656971335411072,0.232122004032135,0.9114202857017517,-1.8375935554504395,1.5914021730422974,-6.3920745849609375,7.040279865264893,-3.7650463581085205,-11.144715309143066,-1.9582208395004272,-0.23758485913276672,0.708053708076477,-5.987797737121582,-2.906890630722046,0.8526133298873901,-1.053579330444336,0.8530845642089844,2.2357239723205566,-1.1146069765090942,2.8735013008117676,2.1092073917388916,5.885324001312256,0.4207947850227356,1.5215656757354736,2.9477412700653076,-8.065391540527344,-0.5684717893600464,-6.008101463317871,-0.2756730616092682,2.543896198272705,3.332164764404297,0.3418108820915222,2.3348562717437744,0.978337824344635,2.0501041412353516,2.1667590141296387,1.698407769203186,0.6653323173522949,1.376716136932373,-0.640019416809082,3.055142641067505,-3.2439229488372803,-3.1012253761291504,-0.12579359114170074,-0.8036290407180786,3.739030361175537,-2.8376717567443848,3.763610601425171,-1.7649226188659668,-0.7061622142791748,0.16238854825496674,3.4607040882110596,-0.49274247884750366,2.1472554206848145,-0.24136261641979218,-4.589475631713867,3.274635076522827,-3.8404147624969482,-0.8840615749359131,2.921112298965454,-6.027283191680908,0.5998716354370117,1.7354985475540161,-6.715281009674072,-1.183276891708374,-4.244085311889648,-1.4338879585266113,-0.617050051689148,-3.8563547134399414,3.5525269508361816,7.997929096221924,1.974561095237732,0.8888853192329407,-3.1947619915008545,-0.8949005603790283,2.7797772884368896,-0.17261090874671936,2.5233733654022217,1.4361166954040527,-0.2877817451953888,-4.238966941833496,-0.7069511413574219,1.2563241720199585,0.1681438684463501,-3.1209304332733154,5.0013909339904785,0.08519387245178223,3.7542433738708496,-5.012990474700928,-0.13710513710975647,-0.44849294424057007,-1.704352855682373,0.6486901044845581,-2.4015095233917236,-6.2497639656066895,1.3706573247909546,0.8377187252044678,-0.717379093170166,-0.8080776333808899,0.37521085143089294,-0.7653496265411377,4.629192352294922,0.929030179977417,-1.2434430122375488,0.46347054839134216,-1.8564012050628662,-7.8217082023620605,-0.21339444816112518,1.8316388130187988,4.101978302001953,5.114486217498779,-2.571929454803467,-2.311342716217041,-2.234525442123413,0.08810672163963318,-2.828357219696045,-2.4902846813201904,1.232200264930725,3.19384503364563,-1.9541374444961548,2.913759708404541,6.006311416625977,2.656639337539673,0.9145083427429199,2.8381729125976562,-2.671642780303955,4.17741584777832,-3.0201942920684814,-3.729379177093506,-6.029414176940918,-4.239853382110596,3.6380269527435303,-2.713352680206299,-4.334053039550781,3.214583396911621,-0.7908580303192139,-7.416345119476318,0.4602765142917633,-2.1040232181549072,3.1886043548583984,-3.0992136001586914,1.2249579429626465,4.965163230895996,0.01729436218738556,2.558152437210083,-3.84110164642334,-1.0491957664489746,-3.126392364501953,3.248880386352539,-0.30486342310905457,2.042506456375122,5.4112935066223145,1.8300367593765259,-0.9058008193969727,1.3343160152435303,-2.6171295642852783,-6.929683685302734,-1.972535490989685,6.0062432289123535,1.9260075092315674,-3.383207321166992,-3.8492207527160645,9.52221965789795,1.4572540521621704,-4.980637073516846,2.6991424560546875,1.9181609153747559,-0.6934746503829956,-2.0809237957000732,4.661496162414551,3.4435782432556152,-3.0821292400360107,-0.6313468813896179,0.9798765778541565,-3.947929620742798,-0.31132972240448,-2.2474863529205322,-3.6283109188079834,-2.5475034713745117,2.034118890762329,-0.552070140838623,2.0807013511657715,5.610440731048584,1.2321410179138184,0.7969173789024353,0.5782943964004517,-0.9306989908218384,1.9199464321136475,-1.502163290977478,-1.8181507587432861,0.34399211406707764,-3.5374202728271484,0.1203935295343399,-2.2010397911071777,-0.508439302444458,-1.1591291427612305,-0.2709539830684662,1.311713695526123,3.7394886016845703,3.6693081855773926,-0.04768263176083565,-4.530552387237549,-0.06502188742160797,-0.13011819124221802,1.2560317516326904,1.451153039932251,5.144979000091553,-5.6785759925842285,-0.10730555653572083,-0.2833428978919983,-1.9433530569076538,1.022195816040039,2.2054049968719482,-9.038715362548828,0.1990351378917694,-0.8053107261657715,1.2520493268966675,2.494400978088379,0.7371733784675598,-0.3170754313468933,-2.2782797813415527,2.10551381111145,0.8790230751037598,-0.047734200954437256,1.3941948413848877,3.969909429550171,0.8405289649963379,-6.269280910491943,6.735415458679199,-1.4189956188201904,2.9995217323303223,-0.22371771931648254,0.5578370094299316,-0.03808218240737915],"type":"scatter3d"},{"hovertemplate":"color=Ariel Sharon<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Ariel Sharon","marker":{"color":"#FFA15A","symbol":"circle"},"mode":"markers","name":"Ariel Sharon","scene":"scene","showlegend":true,"x":[3.612427234649658,-3.76615047454834,1.9014006853103638,-9.589224815368652,6.491860389709473,2.4411919116973877,0.18189062178134918,4.197664737701416,1.2500600814819336,2.2802340984344482,4.899416923522949,2.2112157344818115,7.719526767730713,-5.802183628082275,10.162789344787598,4.501441955566406,-3.407616376876831,0.21378597617149353,0.2433159202337265,-0.7268496751785278,8.420263290405273,1.7188206911087036,11.018080711364746,-1.8065685033798218,-1.3234803676605225,7.174431324005127,-6.759708404541016,8.023015022277832,14.366530418395996,3.505896806716919,0.2166120409965515,-5.191629886627197,-7.85321044921875,-2.402346134185791,-2.6336793899536133,1.292649507522583,-1.0493799448013306,2.9172065258026123,-5.096374988555908,-10.048981666564941,3.8594346046447754,0.6349109411239624,2.557750701904297,7.432138919830322,-11.221755027770996,6.152015686035156,3.464853286743164,13.840500831604004,-2.33551287651062,9.271702766418457,12.922670364379883,-6.146777153015137,-0.7227952480316162,-0.5097880363464355,-1.2330962419509888,0.6875370144844055,-5.453118324279785,0.8409503102302551,-1.5027145147323608,-3.5443673133850098,-0.15366820991039276,9.315605163574219,5.873007774353027,6.948939323425293,6.424312114715576,-0.6975634694099426,20.32723617553711,-3.008082389831543,2.8220205307006836,-1.5047638416290283,16.001455307006836,6.021998882293701,10.784019470214844,-4.449801445007324,8.973578453063965,2.69368314743042,-7.8967132568359375],"y":[5.106990814208984,-7.516014099121094,-2.3134043216705322,-3.0875511169433594,-3.9890265464782715,0.12656038999557495,-1.774937629699707,-4.980276584625244,-0.8312789797782898,-3.3340535163879395,0.9117538928985596,0.04389011859893799,2.3622384071350098,0.39879414439201355,-0.21219752728939056,-2.700561046600342,5.07562780380249,-3.3598268032073975,-1.1658935546875,11.205159187316895,-0.4520750641822815,2.3651845455169678,-6.174410343170166,-0.19823196530342102,-2.614729881286621,-4.587161540985107,-4.414747714996338,12.256394386291504,-3.400566816329956,-1.310349464416504,10.032246589660645,7.160750389099121,3.429654359817505,4.59934663772583,-0.8574124574661255,0.2468116283416748,2.030799627304077,-5.404743671417236,-2.374842643737793,3.5816657543182373,1.826433777809143,-10.564300537109375,3.356057643890381,6.9909772872924805,-6.311893463134766,-1.2037962675094604,-2.4886412620544434,1.6196892261505127,3.6549293994903564,-10.468109130859375,-3.8601179122924805,-4.641347408294678,-6.387240886688232,-8.629777908325195,-3.4669179916381836,4.108513832092285,-5.465781211853027,-4.474512577056885,0.9445599317550659,-1.926720142364502e-05,-0.7124298214912415,3.044461250305176,2.2423224449157715,-0.560617208480835,-2.175584077835083,-3.4844980239868164,5.46894645690918,8.35014820098877,-7.253681659698486,-0.804923415184021,0.3703393340110779,-2.393949508666992,-0.2339155673980713,4.494172096252441,-2.3748373985290527,1.661932349205017,7.361577987670898],"z":[3.606191396713257,-1.2297945022583008,-2.1142077445983887,1.4158395528793335,-1.6361427307128906,1.0739156007766724,0.2964765131473541,1.3409541845321655,-1.7441941499710083,6.044483661651611,-3.2971739768981934,0.30458831787109375,0.3676214814186096,2.0707497596740723,-0.6372938752174377,3.761958122253418,2.3113176822662354,-1.7183990478515625,0.6157127618789673,-11.297054290771484,-3.8793022632598877,1.8631844520568848,-0.5610836148262024,-1.9720470905303955,3.1330018043518066,3.746769666671753,3.314706325531006,-0.5303589105606079,3.3343238830566406,-3.5186233520507812,-5.907895088195801,0.5407928228378296,-4.4142165184021,5.401392459869385,4.40605354309082,-3.39825177192688,0.6068527698516846,-0.6424048542976379,1.0864108800888062,-1.4974838495254517,0.9547051191329956,-2.215188503265381,2.4824447631835938,-1.8874905109405518,6.071786880493164,3.373659133911133,-1.253200650215149,-6.044218063354492,-1.0563271045684814,-0.9362244009971619,3.181581497192383,6.799379348754883,3.5627546310424805,0.7394455671310425,-2.949657678604126,2.897571563720703,2.8243324756622314,-0.23422765731811523,-3.5636963844299316,-3.4839935302734375,-1.1294713020324707,-2.626232385635376,0.8579014539718628,0.5328248739242554,-2.9961040019989014,0.2233668714761734,-4.047324180603027,-1.7599307298660278,-2.656266927719116,0.2933569550514221,-2.546970844268799,2.29687762260437,0.05178797245025635,0.8186907768249512,1.3690330982208252,1.2698962688446045,3.087738513946533],"type":"scatter3d"},{"hovertemplate":"color=Gerhard Schroeder<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Gerhard Schroeder","marker":{"color":"#19d3f3","symbol":"circle"},"mode":"markers","name":"Gerhard Schroeder","scene":"scene","showlegend":true,"x":[-4.911079406738281,-5.144254684448242,-15.088189125061035,-11.227510452270508,-7.414710521697998,-2.4258041381835938,-2.8725764751434326,-13.206740379333496,6.137468338012695,-11.09606647491455,-7.374475002288818,0.5445153117179871,5.922064304351807,-7.493241310119629,7.473963260650635,15.954825401306152,3.506958484649658,7.124451637268066,13.99831485748291,-6.187966823577881,1.362435221672058,-1.1919827461242676,6.756894111633301,-5.443314552307129,0.8537784814834595,6.381587505340576,-8.202048301696777,-1.3556677103042603,-3.3613109588623047,-6.741657733917236,-3.2980124950408936,-3.8698198795318604,-2.3023717403411865,-4.395191669464111,-1.5905274152755737,0.21353118121623993,-6.394644260406494,-8.93008041381836,1.9037331342697144,-8.053303718566895,-1.1065583229064941,1.1803333759307861,-0.22932924330234528,-17.369003295898438,3.020171642303467,3.6177635192871094,3.8336246013641357,4.383111476898193,-10.388998031616211,-8.305027961730957,-1.5772485733032227,-1.813905119895935,-7.931324005126953,2.3311007022857666,5.2264723777771,-6.978898525238037,0.42593297362327576,4.818539619445801,-1.6727858781814575,-8.315020561218262,10.149938583374023,-3.572178840637207,-7.280630588531494,-2.804943084716797,-10.169825553894043,7.284284591674805,3.177225351333618,2.7996795177459717,5.413691520690918,-1.3979538679122925,-12.083346366882324,3.5717873573303223,5.006531238555908,3.387509822845459,0.6015111804008484,-9.033443450927734,-7.412883758544922,-0.1443849802017212,-2.8566904067993164,1.6249397993087769,-7.963143348693848,-13.631604194641113,4.302538871765137,-1.3425559997558594,4.502630233764648,-6.254880905151367,-1.9939744472503662,-0.4446583390235901,0.8648967742919922,7.3608903884887695,-0.22989420592784882,-8.014076232910156,1.6684622764587402,-4.721981048583984,2.661461591720581,-3.4408645629882812,-6.335042953491211,-11.954034805297852,-0.05884785205125809,9.607994079589844,6.348026275634766,2.890717029571533,-9.24276351928711,-7.820247650146484,-1.5621181726455688,-0.18417313694953918,-1.698697805404663,-6.870589733123779,-4.626641273498535],"y":[-5.071978569030762,-3.432098150253296,6.063263893127441,-3.0959768295288086,-0.7756807804107666,-3.033393621444702,-3.6060585975646973,-4.200636863708496,-7.320594310760498,-6.325205326080322,0.9112846851348877,-2.022496223449707,-4.55412483215332,-13.538742065429688,2.8635494709014893,4.896513938903809,-1.3777567148208618,1.8298543691635132,5.678983688354492,4.021143913269043,-0.30772438645362854,-0.17409458756446838,-1.8445855379104614,1.9527298212051392,-1.9125727415084839,0.9398218989372253,-5.351772785186768,1.863469123840332,4.530341625213623,-0.5012341737747192,-2.6773786544799805,1.8531932830810547,3.9383370876312256,-1.4641138315200806,3.353900909423828,-4.281067371368408,4.315276622772217,1.6505268812179565,3.024113893508911,1.8413985967636108,3.389056921005249,2.72670316696167,-4.68561315536499,-1.3471837043762207,1.691896915435791,1.735546588897705,1.542643666267395,1.46565842628479,-2.2960550785064697,8.041698455810547,1.2896469831466675,-0.7285633683204651,-4.573507308959961,1.788805603981018,0.020125895738601685,2.432358741760254,1.6367766857147217,0.4858405590057373,3.1811883449554443,1.7488614320755005,-0.6806811094284058,2.148296356201172,7.460690021514893,2.5060722827911377,-1.2602808475494385,2.8890531063079834,-3.4881932735443115,2.5939972400665283,-0.8852902054786682,3.967100143432617,-11.257460594177246,2.2735230922698975,-0.9759072661399841,-5.535375118255615,6.215405464172363,-1.7575675249099731,-8.620675086975098,4.264209270477295,-1.6084425449371338,-12.462041854858398,7.546438694000244,-6.299864292144775,0.9652668237686157,2.077888011932373,4.961556911468506,-0.022038236260414124,4.521555423736572,3.543614387512207,0.39060455560684204,0.14965645968914032,-2.525601625442505,1.7422024011611938,6.049732208251953,-1.866565227508545,-1.4427220821380615,4.148910999298096,-3.4182050228118896,-1.6421716213226318,-8.820265769958496,5.004727363586426,-2.314589023590088,-2.123966932296753,5.6433186531066895,5.007386207580566,2.208754777908325,2.576768398284912,-2.852297782897949,-0.5209227204322815,-8.138640403747559],"z":[-0.9657846689224243,4.405954360961914,2.3999133110046387,2.3774466514587402,-2.0733230113983154,-1.4853758811950684,-1.2086663246154785,1.9883227348327637,2.5087366104125977,3.98518443107605,-0.9866976141929626,1.6805455684661865,-3.9344234466552734,-0.9295685887336731,-0.8803979158401489,-7.247857570648193,-3.5043201446533203,0.01575601100921631,-7.247985363006592,-2.3181159496307373,0.9330092072486877,0.8717076778411865,-0.25687652826309204,0.17837569117546082,2.0144124031066895,-3.4014687538146973,-5.59417724609375,-0.3567461371421814,-2.1640465259552,-1.5739046335220337,0.6082953214645386,-2.444241523742676,0.6418103575706482,3.665938377380371,-0.7558434009552002,0.8079901337623596,-3.996370553970337,6.873471736907959,6.3832807540893555,1.3580248355865479,1.3314813375473022,-0.4292457103729248,-1.5775227546691895,-2.3504204750061035,0.7755633592605591,-4.76247501373291,-5.162785053253174,-0.15989626944065094,-4.54632043838501,-1.628749132156372,0.6008350849151611,3.260222911834717,-0.9605311751365662,0.9598913192749023,2.628236770629883,3.2178633213043213,-3.087211847305298,2.0636041164398193,-0.7296844124794006,2.1758944988250732,-7.185341835021973,0.4157595932483673,1.926548957824707,-1.946631908416748,8.727311134338379,-1.9351671934127808,0.6506965160369873,-0.6534059047698975,2.2468254566192627,-2.2346394062042236,4.867332935333252,2.2638278007507324,2.4520092010498047,6.327795505523682,-2.5919198989868164,1.3053592443466187,-3.2836508750915527,3.478827714920044,-3.158127784729004,-5.692075729370117,-4.6780571937561035,-5.936744213104248,-2.4094669818878174,-0.8406287431716919,-4.069457530975342,1.775989294052124,1.2101129293441772,0.27982601523399353,0.653989851474762,-0.263374388217926,-0.9095315933227539,-0.7388060092926025,0.5493161082267761,-1.9581081867218018,-2.0476770401000977,3.3114054203033447,-1.488938331604004,0.26835569739341736,4.21541166305542,-3.728858470916748,3.406257152557373,-1.8567914962768555,2.290663003921509,-5.266143798828125,-1.8164787292480469,-1.0524723529815674,-4.835917949676514,-0.0025591254234313965,-6.766846179962158],"type":"scatter3d"},{"hovertemplate":"color=Donald Rumsfeld<br>principal_component_1=%{x}<br>principal_component_2=%{y}<br>principal_component_3=%{z}<extra></extra>","legendgroup":"Donald Rumsfeld","marker":{"color":"#FF6692","symbol":"circle"},"mode":"markers","name":"Donald Rumsfeld","scene":"scene","showlegend":true,"x":[5.179617881774902,-3.940147876739502,1.9316015243530273,-4.7169694900512695,6.568970203399658,-0.4743063449859619,6.800741672515869,4.474223613739014,3.2634165287017822,-5.856104373931885,3.382286787033081,8.357708930969238,6.553560733795166,-1.249129056930542,1.7959344387054443,-3.253143310546875,-9.073342323303223,-3.6820590496063232,6.211515426635742,5.754870891571045,1.6078073978424072,-7.327342987060547,-10.672027587890625,8.286377906799316,1.0425323247909546,-1.655023455619812,1.5165948867797852,-5.187129497528076,8.970078468322754,-6.141376972198486,11.86221694946289,-0.66745924949646,0.7897735238075256,-4.590059280395508,-2.278731346130371,6.7735161781311035,-10.419205665588379,1.850192904472351,10.30034351348877,4.000838756561279,-4.835986614227295,-1.9682753086090088,-5.727268218994141,3.3415863513946533,-8.865339279174805,-1.459335446357727,-10.45351505279541,-17.994712829589844,0.6065545082092285,11.372356414794922,-5.017425537109375,0.3747972846031189,-0.48089274764060974,3.248750686645508,-6.6851115226745605,0.9412834644317627,-0.613103449344635,0.3616117537021637,-1.1983391046524048,-6.091955184936523,-8.921567916870117,3.2894139289855957,-4.6022419929504395,-1.1148297786712646,-3.406137228012085,4.0215582847595215,-6.1550397872924805,-8.785140991210938,9.20678997039795,-4.533265113830566,0.6081000566482544,5.038851737976074,-4.616630554199219,-1.6552505493164062,3.81868577003479,3.723261594772339,-1.9085307121276855,-1.1605839729309082,4.22810173034668,2.4911015033721924,2.268080234527588,-5.447193145751953,-2.2446539402008057,-12.776260375976562,5.341551303863525,-5.702920913696289,0.596591055393219,-3.825533151626587,8.363845825195312,-0.15183012187480927,-2.7226150035858154,10.662556648254395,5.495246887207031,2.6569161415100098,-1.0780000686645508,0.9335656762123108,5.075502872467041,7.677304744720459,-7.321269989013672,-2.6403825283050537,7.144847393035889,-1.9628089666366577,-6.605891227722168,-1.4027026891708374,6.854062557220459,-2.343999147415161,-16.043466567993164,7.651866912841797,-0.19740532338619232,0.16165131330490112,7.512312412261963,2.056828260421753,0.5179715156555176,-2.9147417545318604,8.638337135314941,2.4949567317962646,-0.5690764784812927,0.3206676244735718,-1.3576897382736206,-5.710433006286621,0.05203387886285782],"y":[-9.105780601501465,3.6523807048797607,-6.949173927307129,-1.1079137325286865,5.389835834503174,3.268920660018921,-2.089681625366211,2.7894346714019775,3.977642774581909,-8.947904586791992,1.3280872106552124,-0.3346368670463562,4.330193996429443,4.622323513031006,-4.851999759674072,12.86928939819336,-5.817627906799316,1.9137355089187622,6.604639530181885,-3.7125189304351807,-4.298324108123779,4.90836763381958,-1.320746898651123,-0.8748417496681213,2.987154483795166,-5.446307182312012,4.460779190063477,-5.593723773956299,8.3711519241333,-5.450437545776367,-3.8593039512634277,8.563166618347168,3.668585777282715,0.11132699251174927,-2.805901050567627,2.701059341430664,3.0333263874053955,5.882157802581787,4.250746726989746,2.4271750450134277,0.07681828737258911,-0.3147081434726715,0.09726786613464355,3.153599500656128,2.200315475463867,-1.1655701398849487,4.407175540924072,-0.8501182794570923,-1.462537169456482,5.157785415649414,0.5582371950149536,-7.600793361663818,-9.169235229492188,-3.1009528636932373,2.949259042739868,11.604423522949219,1.2608249187469482,-0.15239393711090088,-1.8866997957229614,2.8055455684661865,1.5349115133285522,-4.072341442108154,-0.45204469561576843,-2.8943545818328857,-3.552509069442749,1.1301039457321167,-4.186418056488037,4.49594783782959,7.84513521194458,-3.694178581237793,0.03364679217338562,5.412825107574463,-5.982430934906006,-3.6680870056152344,-2.0679821968078613,2.602346658706665,2.8783369064331055,-2.7936458587646484,-3.16975998878479,4.715431213378906,-3.3596138954162598,0.6605418920516968,-3.9562580585479736,5.060941219329834,-0.6003344058990479,-5.009340763092041,-2.720499038696289,1.0664689540863037,2.4810993671417236,-0.20299184322357178,4.17086124420166,5.853964805603027,-7.462274074554443,-5.2810959815979,3.806934118270874,0.23783089220523834,3.0462069511413574,-3.656493663787842,-4.258452892303467,-0.9464998841285706,1.4762866497039795,2.6428184509277344,3.2430596351623535,4.233432292938232,-2.888859510421753,2.334089517593384,-5.691112995147705,-9.774800300598145,-9.220766067504883,1.1806780099868774,-1.8121670484542847,-3.1187543869018555,1.4634692668914795,0.13151584565639496,2.7569756507873535,0.3728032112121582,0.45616936683654785,9.63715934753418,-1.1425602436065674,-5.416529178619385,-8.612828254699707],"z":[-2.7919421195983887,-5.648949146270752,2.670811891555786,1.1301977634429932,-1.1751412153244019,-2.621995210647583,0.8500368595123291,2.324557065963745,1.9324392080307007,5.434794902801514,-0.977218747138977,-0.8144817352294922,-5.80776834487915,2.4815220832824707,-0.20065109431743622,-2.138904333114624,-2.204408645629883,5.00666618347168,6.603011608123779,3.9995932579040527,1.9793269634246826,1.8628259897232056,-8.495803833007812,0.007706642150878906,-3.2088961601257324,-4.203146457672119,-1.7168842554092407,3.4478278160095215,-5.8418450355529785,2.9681220054626465,-5.298305511474609,-1.9122674465179443,0.38609758019447327,-0.3208606243133545,-1.9792957305908203,4.342817306518555,-1.8871781826019287,-1.6324348449707031,-2.552351713180542,2.560274839401245,-1.717315673828125,0.3857955038547516,-3.7884793281555176,-6.674859523773193,0.1538938283920288,-0.19410693645477295,1.3332618474960327,-1.4484517574310303,0.08057018369436264,5.7686543464660645,-4.262253284454346,2.709510087966919,-1.868151068687439,-0.586259663105011,-2.982682704925537,1.5574920177459717,-0.8279122710227966,0.9533317685127258,0.7168471813201904,-1.2307817935943604,-2.576753616333008,3.5137863159179688,0.9779092669487,4.049659729003906,1.2825545072555542,2.041053533554077,0.9058914184570312,0.4555138349533081,2.5081698894500732,0.7137683629989624,-0.16279354691505432,-7.2602739334106445,-1.613481879234314,1.9010145664215088,0.7731269001960754,4.367964267730713,4.983439922332764,0.3748430013656616,3.134666919708252,1.2728184461593628,-0.22197085618972778,1.4786170721054077,-1.9365071058273315,-3.7769179344177246,-1.1256674528121948,0.3913036584854126,-0.2728445529937744,1.1509407758712769,3.0286788940429688,2.771003246307373,0.36735206842422485,0.15367361903190613,1.6888060569763184,3.3462836742401123,1.320266842842102,-5.036057949066162,-4.188529014587402,0.26373761892318726,1.757488489151001,-0.6888744831085205,2.0503242015838623,-1.6508865356445312,-4.722657680511475,-4.21692419052124,2.6280782222747803,-4.393911361694336,3.4063329696655273,-0.570380687713623,-6.478588581085205,-1.6780606508255005,0.8277411460876465,-9.329304695129395,0.5045466423034668,-0.7464489340782166,-5.950541019439697,-1.3896689414978027,0.08167126774787903,1.804091215133667,2.6518163681030273,-4.962926864624023,-2.9431161880493164],"type":"scatter3d"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"scene":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"xaxis":{"title":{"text":"principal_component_1"}},"yaxis":{"title":{"text":"principal_component_2"}},"zaxis":{"title":{"text":"principal_component_3"}}},"legend":{"title":{"text":"color"},"tracegroupgap":0},"margin":{"t":60}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('c196d917-af3c-4615-8356-27f54cd14c67');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>
</body>
</html></div></div>
</div>
<p>We see that the Embedding Space of the 3 main components is not very good, the data points are mixed together, so it will be difficult to classify properly.</p>
<p>In fact, Face Recognition applications do not use PCA to extract features. Instead, they will use the Pretrained Model (which has been trained on a large amount of face data) to create Embedded Vector for faces. These pretrained embedded vectors are so good that if we reduce the data dimension to 3 and draw on the graph, we still see that the faces are separated very well.</p>
</section>
</section>
<section id="train-test-split">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Train Test Split</a><a class="headerlink" href="#train-test-split" title="Permalink to this heading">#</a></h3>
<section id="todo-3">
<h4><a class="toc-backref" href="#id9" role="doc-backlink">TODO 3</a><a class="headerlink" href="#todo-3" title="Permalink to this heading">#</a></h4>
<p>Use the <strong>Stratified Split</strong> technique to split the dataset into 2 sets: Train vÃ  Test</p>
<ul class="simple">
<li><p>The train set accounts for 80%</p></li>
<li><p>Shuffle</p></li>
<li><p>Use random seed 42 to maintain the similar result</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of x train:&#39;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of y train:&#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of x test:&#39;</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of y test:&#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of x train: (1030, 7500)
Shape of y train: (1030,)
Shape of x test: (258, 7500)
Shape of y test: (258,)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="feature-extraction-with-pca">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Feature Extraction with PCA</a><a class="headerlink" href="#feature-extraction-with-pca" title="Permalink to this heading">#</a></h3>
<section id="todo-4">
<h4><a class="toc-backref" href="#id11" role="doc-backlink">TODO 4</a><a class="headerlink" href="#todo-4" title="Permalink to this heading">#</a></h4>
<p>HÃ£y dÃ¹ng PCA Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng trÃªn Train Set vÃ  Test Set sao cho pháº§n trÄƒm thÃ´ng tin Ä‘Æ°á»£c giá»¯ láº¡i lÃ  99%.</p>
<p>Name the 2 new variables as <code class="docutils literal notranslate"><span class="pre">x_train_pca</span></code> vÃ  <code class="docutils literal notranslate"><span class="pre">x_test_pca</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="mf">0.99</span><span class="p">)</span> <span class="c1"># 99% information retained</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="c1"># fit on train set</span>

<span class="c1"># transform on train and test set</span>
<span class="n">x_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of Principal Components used:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New train shape:&quot;</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;New test shape:&quot;</span><span class="p">,</span> <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of Principal Components used: 486
New train shape: (1030, 7500)
New test shape: (258, 7500)
</pre></div>
</div>
</div>
</div>
<p>Compare the original face with the approximate face (reconstructed with PCA).</p>
<p>Instead of using math formulas, we use <code class="docutils literal notranslate"><span class="pre">pca.inverse_transform</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
<span class="n">sample_pca</span> <span class="o">=</span> <span class="n">x_train_pca</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">sample_pca</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/71a39bf9def530d917aa3b34244503494946c3f037fd00e72f1b78e04919097e.png" src="../../_images/71a39bf9def530d917aa3b34244503494946c3f037fd00e72f1b78e04919097e.png" />
</div>
</div>
</section>
</section>
<section id="classification-with-knn">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Classification with KNN</a><a class="headerlink" href="#classification-with-knn" title="Permalink to this heading">#</a></h3>
<section id="todo-5">
<h4><a class="toc-backref" href="#id13" role="doc-backlink">TODO 5</a><a class="headerlink" href="#todo-5" title="Permalink to this heading">#</a></h4>
<ul>
<li><p>Train K-NN models to classify faces on extracted datasets after applying PCA</p>
<ul class="simple">
<li><p>Experiment with different <code class="docutils literal notranslate"><span class="pre">k</span></code> to find the best model.</p></li>
<li><p>Call function <code class="docutils literal notranslate"><span class="pre">score</span></code> to view Accuracy on Train Set and Test Set</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on Train Set&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy on Test Set&#39;</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pca</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">13</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy on Train Set: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train_pca</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1"> %&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy Test Set: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pca</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1"> %&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on Train Set: 53.88 %
Accuracy Test Set: 30.23 %
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># Define a function to experiment with various k parameters by looping</span>
<span class="k">def</span> <span class="nf">train_knn_model</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
  <span class="n">knn_model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">)</span>
  <span class="n">knn_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;K=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2"> --- Train Accuracy: </span><span class="si">{</span><span class="n">train_accuracy</span><span class="si">}</span><span class="s2"> --- Test Accuracy: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">25</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">knn_model</span><span class="p">,</span> <span class="n">test_accuracy</span>

<span class="n">best_test_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
  <span class="n">current_model</span><span class="p">,</span> <span class="n">current_test_accuracy</span> <span class="o">=</span> <span class="n">train_knn_model</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">x_train_pca</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test_pca</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
  <span class="c1"># Check the test accuracy, if better -&gt; update</span>
  <span class="k">if</span> <span class="n">current_test_accuracy</span> <span class="o">&gt;</span> <span class="n">best_test_accuracy</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Update to best model with k = </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Accuracy of best model: </span><span class="si">{</span><span class="n">current_test_accuracy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">current_model</span>
    <span class="n">best_test_accuracy</span> <span class="o">=</span> <span class="n">current_test_accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>K=2 --- Train Accuracy: 0.7854368932038835 --- Test Accuracy: 0.5116279069767442
-------------------------
------------------------------
Update to best model with k = 2
Test Accuracy of best model: 0.5116279069767442
------------------------------
K=5 --- Train Accuracy: 0.7271844660194174 --- Test Accuracy: 0.562015503875969
-------------------------
------------------------------
Update to best model with k = 5
Test Accuracy of best model: 0.562015503875969
------------------------------
K=8 --- Train Accuracy: 0.6737864077669903 --- Test Accuracy: 0.5658914728682171
-------------------------
------------------------------
Update to best model with k = 8
Test Accuracy of best model: 0.5658914728682171
------------------------------
K=11 --- Train Accuracy: 0.6514563106796116 --- Test Accuracy: 0.5852713178294574
-------------------------
------------------------------
Update to best model with k = 11
Test Accuracy of best model: 0.5852713178294574
------------------------------
K=14 --- Train Accuracy: 0.6368932038834951 --- Test Accuracy: 0.562015503875969
-------------------------
K=17 --- Train Accuracy: 0.6174757281553398 --- Test Accuracy: 0.5426356589147286
-------------------------
K=20 --- Train Accuracy: 0.6029126213592233 --- Test Accuracy: 0.5232558139534884
-------------------------
K=23 --- Train Accuracy: 0.5941747572815534 --- Test Accuracy: 0.5038759689922481
-------------------------
K=26 --- Train Accuracy: 0.5650485436893203 --- Test Accuracy: 0.5232558139534884
-------------------------
K=29 --- Train Accuracy: 0.5563106796116505 --- Test Accuracy: 0.5193798449612403
-------------------------
K=32 --- Train Accuracy: 0.5524271844660195 --- Test Accuracy: 0.5116279069767442
-------------------------
K=35 --- Train Accuracy: 0.5485436893203883 --- Test Accuracy: 0.5077519379844961
-------------------------
K=38 --- Train Accuracy: 0.5427184466019418 --- Test Accuracy: 0.5116279069767442
-------------------------
K=41 --- Train Accuracy: 0.5368932038834952 --- Test Accuracy: 0.5271317829457365
-------------------------
K=44 --- Train Accuracy: 0.5349514563106796 --- Test Accuracy: 0.5077519379844961
-------------------------
K=47 --- Train Accuracy: 0.5242718446601942 --- Test Accuracy: 0.5077519379844961
-------------------------
K=50 --- Train Accuracy: 0.5184466019417475 --- Test Accuracy: 0.5155038759689923
-------------------------
K=53 --- Train Accuracy: 0.5106796116504855 --- Test Accuracy: 0.5232558139534884
-------------------------
K=56 --- Train Accuracy: 0.5087378640776699 --- Test Accuracy: 0.5348837209302325
-------------------------
K=59 --- Train Accuracy: 0.5058252427184466 --- Test Accuracy: 0.5271317829457365
-------------------------
K=62 --- Train Accuracy: 0.5029126213592233 --- Test Accuracy: 0.5155038759689923
-------------------------
K=65 --- Train Accuracy: 0.5009708737864078 --- Test Accuracy: 0.5155038759689923
-------------------------
K=68 --- Train Accuracy: 0.5029126213592233 --- Test Accuracy: 0.5155038759689923
-------------------------
</pre></div>
</div>
</div>
</div>
</section>
<section id="todo-6">
<h4><a class="toc-backref" href="#id14" role="doc-backlink">TODO 6</a><a class="headerlink" href="#todo-6" title="Permalink to this heading">#</a></h4>
<p>Use the <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> metrics to print out the accuracy of the model for each person in the Test set</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR SOLUTION</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                   precision    recall  f1-score   support

     Ariel Sharon       0.20      0.06      0.10        16
     Colin Powell       0.51      0.72      0.60        47
  Donald Rumsfeld       0.89      0.33      0.48        24
    George W Bush       0.62      0.91      0.73       106
Gerhard Schroeder       0.57      0.18      0.28        22
      Hugo Chavez       0.00      0.00      0.00        14
       Tony Blair       0.57      0.28      0.37        29

         accuracy                           0.59       258
        macro avg       0.48      0.35      0.37       258
     weighted avg       0.55      0.59      0.53       258
</pre></div>
</div>
</div>
</div>
</section>
<section id="todo-7">
<h4><a class="toc-backref" href="#id15" role="doc-backlink">TODO 7</a><a class="headerlink" href="#todo-7" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Try graphing faces to compare the predicted results of the KNN model with the actual label (random 5 photos per person, for example). Suggested steps:</p>
<ul>
<li><p>Random out 5 photos in the Test episode belonging to each person (0 - 6)</p></li>
<li><p>Use trained models to predict names</p></li>
<li><p>Draw shapes, display the correct peopleâ€™s names and peopleâ€™s names predicted by the model</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">num_people</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">num_images</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_people</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>

<span class="k">for</span> <span class="n">person</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_people</span><span class="p">):</span>
   <span class="n">indexes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">person</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
   <span class="n">random_5_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">indexes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_images</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

   <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_images</span><span class="p">):</span>
      <span class="n">axes</span><span class="p">[</span><span class="n">person</span><span class="p">][</span><span class="n">image</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
      <span class="n">axes</span><span class="p">[</span><span class="n">person</span><span class="p">][</span><span class="n">image</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

      <span class="n">image_index</span> <span class="o">=</span> <span class="n">random_5_images</span><span class="p">[</span><span class="n">image</span><span class="p">]</span>
      <span class="n">axes</span><span class="p">[</span><span class="n">person</span><span class="p">][</span><span class="n">image</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="n">image_index</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>

      <span class="n">person_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test_pca</span><span class="p">[</span><span class="n">image_index</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">486</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">axes</span><span class="p">[</span><span class="n">person</span><span class="p">][</span><span class="n">image</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;true: </span><span class="si">{</span><span class="n">target_names</span><span class="p">[</span><span class="n">person</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2"> predicted: </span><span class="si">{</span><span class="n">target_names</span><span class="p">[</span><span class="n">person_pred</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/16615d29da56480a096c3c3aa1ae8f0f58bd62d2df7a7ed6f0199be79e8bf502.png" src="../../_images/16615d29da56480a096c3c3aa1ae8f0f58bd62d2df7a7ed6f0199be79e8bf502.png" />
</div>
</div>
</section>
</section>
</section>
<section id="problem-2-console-game-semantris-3-points">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Problem 2: Console game Semantris (3 points)</a><a class="headerlink" href="#problem-2-console-game-semantris-3-points" title="Permalink to this heading">#</a></h2>
<p>In this article, we will make 1 simple game running on the Python console window. This game simulates Googleâ€™s Sementris game, please try it at <a class="reference external" href="https://research.google.com/semantris/">here</a> (choose Play Arcade)</p>
</section>
<section id="guildance">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Guildance</a><a class="headerlink" href="#guildance" title="Permalink to this heading">#</a></h2>
<p>Given the pre-trained AI model below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">module_url</span> <span class="o">=</span> <span class="s2">&quot;https://tfhub.dev/google/universal-sentence-encoder/4&quot;</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">module_url</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This model is capable of converting English words into vectors</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">([</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;dog&quot;</span><span class="p">,</span> <span class="s2">&quot;chihuahua&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;numpy.ndarray&#39;&gt;
(3, 512)
</pre></div>
</div>
</div>
</div>
<p>Báº¡n hÃ£y thiáº¿t káº¿ 1 game dá»±a theo <a class="reference external" href="https://drive.google.com/file/d/1WQdZGszYniiBzoDpdx-VWEIyNz2rFvip/view?usp=sharing">This diagram</a></p>
<p>LÆ°u Ã½</p>
<ul class="simple">
<li><p>File <code class="docutils literal notranslate"><span class="pre">words.txt</span></code> Download <a class="reference external" href="https://drive.google.com/file/d/1KYMBK_j3g7_ROEJ46Nb0PmUerY5Xdyx_/view?usp=sharing">here</a></p></li>
<li><p>you need to <code class="docutils literal notranslate"><span class="pre">strip</span></code> and <code class="docutils literal notranslate"><span class="pre">lowercase</span></code> value <code class="docutils literal notranslate"><span class="pre">y</span></code></p></li>
<li><p>values of <code class="docutils literal notranslate"><span class="pre">y</span></code> should not be duplicated with <code class="docutils literal notranslate"><span class="pre">x</span></code></p></li>
<li><p>Users only have 3 lives for the entire game.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;Problem_2_words.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of words in file txt: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of words in file txt: 476
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">time</span>
<span class="k">def</span> <span class="nf">consine_similarity</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
  <span class="n">pab</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)))</span>
  <span class="n">norm_A</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)))</span> <span class="o">**</span> <span class="mf">0.5</span>
  <span class="n">norm_B</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)))</span> <span class="o">**</span> <span class="mf">0.5</span>
  <span class="k">return</span> <span class="n">pab</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm_A</span> <span class="o">*</span> <span class="n">norm_B</span><span class="p">)</span>

<span class="n">list_similarity</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">def</span> <span class="nf">find_4_most_similar_word</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
    <span class="n">list_similarity</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">consine_similarity</span><span class="p">(</span><span class="n">embedding_y</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">score_or_not</span><span class="p">(</span><span class="n">list_similarity</span><span class="p">):</span>
  <span class="n">list_similarity</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">list_similarity</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="n">list_similarity</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]:</span>
      <span class="k">return</span> <span class="kc">True</span>
  <span class="k">return</span> <span class="kc">False</span>


<span class="c1"># main function</span>
<span class="n">score</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">blood</span> <span class="o">=</span> <span class="mi">3</span>
<span class="k">while</span><span class="p">(</span><span class="n">score</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">and</span> <span class="n">blood</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">):</span>
  <span class="c1"># display</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Your score is: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Your blood is: </span><span class="si">{</span><span class="n">blood</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

  <span class="c1"># start game</span>
  <span class="n">num_words</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">num_words</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">y</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Enter one word which is semantically similar with </span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">: &quot;</span><span class="p">)</span>
  <span class="n">embedding_y</span> <span class="o">=</span> <span class="n">model</span><span class="p">([</span><span class="n">y</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">find_4_most_similar_word</span><span class="p">()</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">score_or_not</span><span class="p">(</span><span class="n">list_similarity</span><span class="p">)):</span>
    <span class="n">score</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">score</span> <span class="o">==</span> <span class="mi">10</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You won&quot;</span><span class="p">)</span>
      <span class="k">break</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">blood</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blood</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Game over&quot;</span><span class="p">)</span>
      <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Your score is: 0
Your blood is: 3
Enter one word which is semantically similar with ice cream: creamy
Your score is: 1
Your blood is: 3
Enter one word which is semantically similar with computer: technology
Your score is: 2
Your blood is: 3
Enter one word which is semantically similar with night: moon
Your score is: 3
Your blood is: 3
Enter one word which is semantically similar with helmet: bike
Your score is: 3
Your blood is: 2
Enter one word which is semantically similar with boat: ship
Your score is: 4
Your blood is: 2
Enter one word which is semantically similar with cop: police
Your score is: 5
Your blood is: 2
Enter one word which is semantically similar with pond: water
Your score is: 5
Your blood is: 1
Enter one word which is semantically similar with wheat: rice
Game over
CPU times: user 1.18 s, sys: 106 ms, total: 1.29 s
Wall time: 48.4 s
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/Session1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="S1_ASM.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Session 1: Assigment</p>
      </div>
    </a>
    <a class="right-next"
       href="Session%201%20Revision.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Session 1: Revision</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-face-recognition-with-pca-and-knn-7-popints">Problem 1: Face Recognition with PCA and KNN (7 popints)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-dataset">Prepare the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-the-data">Analyze the data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-pca-to-reduce-data-dimension-and-draw-embedding-space">Use PCA to reduce data dimension and draw Embedding Space</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-1">TODO 1</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-2">TODO 2</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-test-split">Train Test Split</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-3">TODO 3</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction-with-pca">Feature Extraction with PCA</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-4">TODO 4</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-with-knn">Classification with KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-5">TODO 5</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-6">TODO 6</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#todo-7">TODO 7</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2-console-game-semantris-3-points">Problem 2: Console game Semantris (3 points)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guildance">Guildance</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kyle Paul
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>