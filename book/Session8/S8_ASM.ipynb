{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqiNuiX1ebqB"
      },
      "source": [
        "# Session 8: Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9X5OlOdLNyp"
      },
      "source": [
        "## Classic filter types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk1asxZZn9Mk"
      },
      "source": [
        "- The Deep Convolutional Neural Network model essentially learns filters to be able to extract features in the data set (the numbers in the filter are the weights to learn)\n",
        "- The concept of filter and convolution has been around for a long time, filters at that time were hand-crafted and each filter only had 1 effect.\n",
        "- The following section will go through the 2 most basic filters, which are vertical and horizontal edge detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnDbJFT0NAzD"
      },
      "source": [
        "**Download sample image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B68ethDtLa9q",
        "outputId": "21a92eb0-b58d-4aca-e995-6af95e19c0b9"
      },
      "outputs": [],
      "source": [
        "!wget https://i.imgur.com/kbWNDCh.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8zQim5wSpBG"
      },
      "source": [
        "**Read the image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "NPikGqriLzVs",
        "outputId": "83d7bd30-3160-4e92-c7d7-15f541dc038e"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# read the image with Pillow\n",
        "img = Image.open('kbWNDCh.png').convert('L')\n",
        "\n",
        "# convert into numpy array\n",
        "img = np.array(img)\n",
        "\n",
        "# show the image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img, cmap='gray')  # imshow function receive an numpy array\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOKGfr50SrrW"
      },
      "source": [
        "**Create a filter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "bsWMOOxKNC9q",
        "outputId": "3fe8b109-a9fc-4138-df31-7bd748005370"
      },
      "outputs": [],
      "source": [
        "filter_vertical = np.array([\n",
        "  [10, 0, -10],\n",
        "  [10, 0, -10],\n",
        "  [10, 0, -10]\n",
        "])\n",
        "\n",
        "plt.imshow(filter_vertical, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqqHWHjtS9Dd"
      },
      "source": [
        "Looking at the newly created filter, we see that the brightness of the filter changes horizontally $\\rightarrow$ filter capable of detecting vertical strokes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWnyRPY1SvUI"
      },
      "source": [
        "Perform convolution operation with ``padding='same'``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "D40YyhMS4I_S",
        "outputId": "67b04b5d-1126-48b2-83fa-79eb3496cd6d"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import convolve\n",
        "\n",
        "res_vertical = convolve(img, filter_vertical, mode='same', method='direct')\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(res_vertical, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au6bmf5PTQFx"
      },
      "source": [
        "Observing the results we see that:\n",
        "- At vertical edges, the results are easy to see\n",
        "- At oblique edges, we get faint results\n",
        "- On horizontal edges, the result is very blurry or none at all\n",
        "\n",
        "We continue to experiment with horizontal edge detection filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "ctcAXSUvpCnJ",
        "outputId": "67c7d597-49e5-48e1-bd4f-4b0007d3a5c1"
      },
      "outputs": [],
      "source": [
        "filter_horizontal = np.array([\n",
        "  [10, 10, 10],\n",
        "  [0, 0, 0],\n",
        "  [-10, -10, -10]\n",
        "])\n",
        "\n",
        "plt.imshow(filter_horizontal, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "BD0rtK76pZ4V",
        "outputId": "8336d75a-49fb-435a-b6eb-78ef0ab29dd1"
      },
      "outputs": [],
      "source": [
        "res_horizontal = convolve(img, filter_horizontal, mode='same', method='direct')\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(res_horizontal, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhttgAFpfyB"
      },
      "source": [
        "So how to detect horizontal and vertical edges at the same time?\n",
        "\n",
        "Let's just add up the above 2 results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "BhkzTDTLpmZO",
        "outputId": "9d9799d8-f01b-49c0-9830-1a9d30a75592"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(res_vertical + res_horizontal, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRtm-yXpp7OM"
      },
      "source": [
        "There are many other types of filters, you can refer to in the lecture slide or Google, then apply it to the above lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afNhLathkqTL"
      },
      "source": [
        "# The problem of recognizing diseases for cowpea leaves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE1AvL4tvXH8"
      },
      "source": [
        "In this Assignment, we will use CNN to classify whether the leaves of beans belong to be sick or not.\n",
        "- Normal leaves\n",
        "- Angular Leaf spot\n",
        "- Bean Rust\n",
        "\n",
        "We will load the available dataset of Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m637wOjHt4QX"
      },
      "source": [
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ol-li4Iw9ib"
      },
      "source": [
        "**Download data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEBtIo25t8Aq"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "(train, val, test), info = tfds.load('beans',\n",
        "                                      split=['train', 'validation', 'test'],\n",
        "                                      shuffle_files=True,\n",
        "                                      as_supervised=True,\n",
        "                                      with_info=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "149Ng_cNw_ee"
      },
      "source": [
        "**View dataset description**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_6ecSWt8Q9",
        "outputId": "3fbb6ede-c093-4e5c-aa69-47dc3d8c7b7d"
      },
      "outputs": [],
      "source": [
        "print(info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuWD1jXdPNqR"
      },
      "source": [
        "**Check out the images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FgKvjGgfCJgT",
        "outputId": "03b23ab3-74c8-4e88-ad5f-95236cdb2fec"
      },
      "outputs": [],
      "source": [
        "tfds.show_examples(train, info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQLMQBvTZk0"
      },
      "source": [
        "To make it easier to code, we will convert all data to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHmekn2p7xNj"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp6TDDUf45Uk",
        "outputId": "18d2d241-a10b-4f64-9a51-41ce64eef773"
      },
      "outputs": [],
      "source": [
        "train_label = []\n",
        "train_image = []\n",
        "\n",
        "for image, label in tfds.as_numpy(train):\n",
        "  train_image.append(image)\n",
        "  train_label.append(label)\n",
        "\n",
        "train_image = np.array(train_image)\n",
        "train_label = np.array(train_label)\n",
        "\n",
        "print(\"Train Set\")\n",
        "print(\"Shape:\", train_image.shape, train_label.shape)\n",
        "print(\"Label distribution:\", np.unique(train_label, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wViEandV54qz",
        "outputId": "fc2dd928-6885-4ed5-ed19-a526f5f2271a"
      },
      "outputs": [],
      "source": [
        "val_label = []\n",
        "val_image = []\n",
        "\n",
        "for image, label in tfds.as_numpy(val):\n",
        "  val_image.append(image)\n",
        "  val_label.append(label)\n",
        "\n",
        "val_image = np.array(val_image)\n",
        "val_label = np.array(val_label)\n",
        "\n",
        "print(\"Validation Set\")\n",
        "print(\"Shape:\", val_image.shape, val_label.shape)\n",
        "print(\"Label distribution:\", np.unique(val_label, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UiMK5qQ6B7L",
        "outputId": "c06cb5ca-4de5-4d76-cc4c-2bf214b63f6c"
      },
      "outputs": [],
      "source": [
        "test_label = []\n",
        "test_image = []\n",
        "for image, label in tfds.as_numpy(test):\n",
        "  test_image.append(image)\n",
        "  test_label.append(label)\n",
        "test_image = np.array(test_image)\n",
        "test_label = np.array(test_label)\n",
        "print(\"Test Set\")\n",
        "print(\"Shape:\", test_image.shape, test_label.shape)\n",
        "print(\"Label distribution:\", np.unique(test_label, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCrbNqpf6JqF"
      },
      "outputs": [],
      "source": [
        "# Remove unnecessary variables\n",
        "del train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xV1_xcfxyTM"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkg2Nr7dx0Nn"
      },
      "source": [
        "With visual-style data, data generation is quite simple, 1 few examples\n",
        "- Pixel shifting\n",
        "- Rotation\n",
        "- Flip\n",
        "- Zoom-in/out\n",
        "- Change color\n",
        "\n",
        "\n",
        "Generating more data gives the model the ability to generalize better when used in practice. At the same time, when we have a lot of data, we also partly reduce overfitting.\n",
        "\n",
        "There are 2 ways to augment data:\n",
        "- Offline: augment first, save images and then train\n",
        "- Online: augmented during training (before putting images into the model)\n",
        "\n",
        "The commonly used Online Augmentation technique is called Random Augmentation, for example:\n",
        "- Create a pipeline consisting of 4 augmented steps as above, each step is assigned 1 probability: do or do not do, the input of step `n` is the result of step `n-1`\n",
        "- In each step: Create 1 range of random values to perform Augment (how many pixels to shift, how many degrees to rotate, how much zoom-in/out)\n",
        "- The input image will be fed through the above pipeline → the probability that image A in epoch 2 will be augmented like image A in epoch 1 is very unlikely -> the model is almost trained with an infinite number of images.\n",
        "\n",
        "`tensorflow.keras` supports Online Augmentation with layers (note, in `tf.keras` each layer we have no control over the probability of execution / non-execution), the pipeline is built using the `Sequential` API. Supported layers include:\n",
        "- `RandomBrightness`\n",
        "- `RandomContrast`\n",
        "- `RandomCrop`\n",
        "- `RandomFlip`\n",
        "- `RandomHeight`\n",
        "- `RandomRotation`\n",
        "- `RandomTranslation`\n",
        "- `RandomWidth`\n",
        "- `RandomZoom`\n",
        "\n",
        "You can read all the parameters of the above layers [at this document](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YczA_Q61bt4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomBrightness, RandomContrast, RandomCrop, RandomHeight, RandomTranslation, RandomWidth, RandomZoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1WyY8451C0M"
      },
      "outputs": [],
      "source": [
        "# Simple Augment Pipeline example consists of 2 flip and rotate steps\n",
        "# Instead of augmentor.add(layer), we put the layer at initialization\n",
        "\n",
        "augmentor = Sequential([\n",
        "  Input(shape=(500,500,3)),\n",
        "  RandomFlip(\"horizontal_and_vertical\"),\n",
        "  RandomRotation(0.2), # Read the document to understand the meaning behind 0.2\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bI9lXzhW4pVw",
        "outputId": "f1d54795-e2c0-42a8-ded8-214c420c1eba"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = train_image[0]\n",
        "image = np.expand_dims(image, axis=0)  # add the batch dimension\n",
        "print(image.shape)\n",
        "\n",
        "'''\n",
        "Put images into the Augmentor 9 times -> can produce 9 different images\n",
        "  - Augment and convert the data type back to numpy\n",
        "  - Augment only occurs when calling Augmentor(image) or when train using the fit function\n",
        "  - Delete the first dimension (batch size) to plot with matplotlib with squeeze()\n",
        "  - After augmentation is complete, there will be a dtype of float\n",
        "  - We haven't normalized the image yet, so pyplot doesn't understand the 0-255 float data as an image\n",
        "  - Convert back to int\n",
        "'''\n",
        "\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  augmented_image = augmentor(image).numpy()\n",
        "  augmented_image = augmented_image.squeeze()\n",
        "  augmented_image = augmented_image.astype(int)\n",
        "  plt.imshow(augmented_image)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtcYGEC_OGew"
      },
      "source": [
        "**Try other augmentation techniques**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAFwveNjM8Ws"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION HERE (OPTIONAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAnCNmUhPBql"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "68bdl-uREqUP",
        "outputId": "2cea581d-8578-49d6-c641-86bd0849ff1a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image = train_image[0]\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Augmentation will not take place when calling predict (inference)\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  # Predict function returs Numpy Array\n",
        "  augmented_image = augmentor.predict(image, verbose=0) # verbose = 0 -> no progress bar\n",
        "  augmented_image = augmented_image.squeeze()\n",
        "  augmented_image = augmented_image.astype(int)\n",
        "  plt.imshow(augmented_image)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap_EtC2_HmeH"
      },
      "source": [
        "## Rescaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJoPy2a473ar"
      },
      "source": [
        "Normally, we will normalize the image by dividing 255 and the image data type will now be `float` instead of `int`, saving the `float` will take more RAM than `int` and this data set is relatively large (image 500x500 pixels) so we will not normalize first but will integrate this normalize step into the model\n",
        "- The first layer in the model is `Input`\n",
        "- The next layer is [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling`)\n",
        "\n",
        "\n",
        "Usage example\n",
        "```python\n",
        "from tensorflow.keras.layers import Rescaling, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(3, 3, 3)))\n",
        "model.add(Rescaling(scale=1./255))\n",
        "# ... next layers\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bhSY8_Ap1-9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Rescaling, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(3, 3, 3)))\n",
        "model.add(Rescaling(scale = 1./255))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGG8VjUtAA_j",
        "outputId": "099c1835-d643-4111-dd25-07cbd5e9ddd1"
      },
      "outputs": [],
      "source": [
        "# run to see the results\n",
        "t = np.ones(shape=(1,3,3,3)) * 255\n",
        "print(t)\n",
        "t = model.predict(t)\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aYX15GHKyMG"
      },
      "source": [
        "## Global Average Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75o_BeDdK1Cj"
      },
      "source": [
        "In the theory Lab, we see that CNNs final feature map will be `Flatten` before passing to the `Dense` layer\n",
        "\n",
        "The fact that `Flatten` has 1 drawback is that if the final feature map is large, we will have a lot of weight in the `Dense` layer → FLOPs are high → train long.\n",
        "\n",
        "A more common practice is that instead of using `Flatten` we will use the layer `GlobalAveragePooling2D`\n",
        "\n",
        "This layer will average each feature map → if in the last Convolution layer we have 512 feature maps, the result of `GlobalAveragePooling2D` will be a 512-dimensional vector → reduce FLOPs and a lot of weight in the `Dense` layer\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "# ...\n",
        "# replace layer Flatten()\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(...))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q13lspBp5l_h"
      },
      "source": [
        "## Build the architecture of model and start training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZNiAUzzEXzF"
      },
      "source": [
        "#### TODO: READ CAREFULLY BEFORE CODING\n",
        "- Build the Augmentation Pipeline of your own\n",
        "- Build CNN model (layer `Rescaling` is required)\n",
        "  - Recode the models yourself in the Lab\n",
        "  - Because the input image is quite large, you may have to use multiple `Convolution-Batchnorm-Relu` blocks instead of just 3.\n",
        "  - The architecture of VGG-16 is very easy to understand. Try searching Google and implementing this architecture (reduce the number of layers, there is no need for 16 layers because the train takes a long time)\n",
        "  - You need to use `SeparableConv2D` instead of `Conv2D` and `GlobalAveragePooling2D` instead of `Flatten` to reduce FLOPs and the number of weights to be able to train using Colab.\n",
        "- Connect Augmentation Pipeline and CNN with another `Sequential` (Because when inference, the augmentation pipeline will be disabled, so we can completely use it in real application)\n",
        "- Train the model, and make predictions on the Test set(Confusion Matrix, Classification Report)\n",
        "  - If encountering error `Out of Memory`, you should reduce the number of `batch_size` when training\n",
        "- Draw some pictures to see the predicted results of the model.\n",
        "- The training may be a bit long, you can make tea or coffee to enjoy while looking at the train screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20mKRO-qschJ"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION - CNN here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuJevDRkhDf5"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION - confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul-kg900hgPa"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION - classification report"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
