{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhKpwiVXnRdU"
      },
      "source": [
        "# Session 2: Assigment\n",
        "\n",
        "```{contents}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot3H1ae5_TaG"
      },
      "source": [
        "## Hand-written digit Recognition with PCA and Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfwdqeY2_hxe"
      },
      "source": [
        "We will practice using Softmax Regression in combination with PCA to classify handwritten digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th1baCGEZn-3"
      },
      "source": [
        "### Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gq5ZJk63eyJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOTzrh-KZsVU",
        "outputId": "4ee2ceac-616c-49ad-e79f-d45697548e85"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Shape of x_train:',x_train.shape)\n",
        "print('Shape of y_train:',y_train.shape)\n",
        "print('-'*10)\n",
        "print('Shape of x_test:',x_test.shape)\n",
        "print('Shape of y_test:',y_test.shape)\n",
        "print('-'*10)\n",
        "print('Labels:', np.unique(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq9hUZCrZz0z"
      },
      "source": [
        "From the results printed above, we understand that the Train data consists of 60,000 images, each of which is a gray image with a size of 28x28 (if the image is RGB $\\rightarrow$ shape is `[n_sample, width, height, 3]` in which 3 is the color channel.)\n",
        "\n",
        "The Test set consists of 10000 images\n",
        "\n",
        "The dataset consists of 10 labels, numbered from 0 to 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOlVLXs7aGFt"
      },
      "source": [
        "## Visualize images in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eKhdyWTA38rb",
        "outputId": "40e35299-73db-408f-fc06-65874758140f"
      },
      "outputs": [],
      "source": [
        "n_rows = 10\n",
        "n_cols = 5\n",
        "fig, axs = plt.subplots(n_rows, n_cols, figsize=(7, 15))\n",
        "for row in range(n_rows):\n",
        "  for col in range(n_cols):\n",
        "    random_index = np.random.choice(np.where(y_train == row)[0])\n",
        "    axs[row][col].grid('off')\n",
        "    axs[row][col].axis('off')\n",
        "    axs[row][col].imshow(x_train[random_index], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjNfNb-gdkL9"
      },
      "source": [
        "### Perform PCA to reduce the dimension of dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfP8qiusb8-I"
      },
      "source": [
        "Most algorithms of `sklearn` are only applicable on 2-dimensional data `(n_sample, n_feature)`. Since our dataset is in image form, we need to `flatten` the data before doing PCA `(n_sample, 28, 28)` → `(n_sample, 28 * 28)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d449xXa47yS",
        "outputId": "1518c153-fa59-40fd-db65-28df91f5eadd"
      },
      "outputs": [],
      "source": [
        "x_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "print('x_train shape after flatten', x_train_flatten.shape)\n",
        "print('x_test shape after flatten', x_test_flatten.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fe8q9DeaiXd"
      },
      "source": [
        "#### TODO 1\n",
        "\n",
        "Apply PCA to the above dataset to extract features so that the amount of information retained is 99%. Print out the number of key components used.\n",
        "\n",
        "Remember to apply `StandardScaler` to normalize data before performing PCA (in session 1, because the dataset is already `/255`, we skip this step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIoitdYPk0tH"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOXK-7wsdWAx"
      },
      "source": [
        "#### Optional 1\n",
        "You can refer to Assignment 1 to visualize the results of applying PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "D903mm31-o2F",
        "outputId": "1464f25c-f537-4b00-f8cf-69fcd4bf5b66"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOHSTIdOeFKO"
      },
      "source": [
        "## One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0X_V6HWeJCY"
      },
      "source": [
        "![ohe](https://i.imgur.com/mtimFxh.png)\n",
        "\n",
        "One Hot Encoding also has the following probabilistic meanings:\n",
        "- Observing line 1, we see that there is a number 1 in column Red and a number 0 in column Yellow, Green. This means that the probability that the sample has a Red label is 100%, the rest is 0%\n",
        "- Recall that in the multi-class classification problem, we use the Softmax function to turn regression scores into probabilities. Example:\n",
        "\n",
        "Red | Yellow | Green\n",
        "--- | --- | ---\n",
        "0.8 | 0.1 | 0.1\n",
        "\n",
        "- Now thanks to One Hot Encoding, we can use the Cross Entropy formula to calculate the error between the predicted machine probability and the actual probability.\n",
        "$$\n",
        "\\text{Cross Entropy} = -\\sum{y \\times \\text{ln}(\\hat{y})}\n",
        "$$\n",
        "\n",
        "  - With $y$ is the ground truth and $\\hat{y}$ is the probability predicted from model\n",
        "\n",
        "How to apply one-hot encoding on ``y_train`` và ``y_test``\n",
        "- Import module\n",
        "  ```\n",
        "  from tensorflow.keras.utils import to_categorical\n",
        "  ```\n",
        "- Call method\n",
        "  ```\n",
        "  y_train_encode = to_categorical(y_train, num_classes=...)\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nScsm2l2BVen"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3BjFWeKe9LK"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_ovVsXPfBPi"
      },
      "source": [
        "#### TODO 2\n",
        "\n",
        "Follow these steps\n",
        "- Build and train the Softmax Regression model\n",
        "- Evaluate the performane of model with method `model.evaluate()` on the test set `(x_test_pca, y_test_encode)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6lLOK6ufAAE",
        "outputId": "f149120d-4b02-408c-d8e7-d8357528b97d"
      },
      "outputs": [],
      "source": [
        "# YOUR SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08dVvrTDhF4g"
      },
      "source": [
        "###  Test the predicted results of the model on the Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9v_3VQBhOF7"
      },
      "source": [
        "First, we need to use the model to predict the label for all the images in the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZBjA0RnhNY0",
        "outputId": "f5b5099c-be2c-4932-c03e-f5f11e797a6c"
      },
      "outputs": [],
      "source": [
        "y_test_pred_prob = model.predict(x_test_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRTQ7_2yhu3P"
      },
      "source": [
        "Since `y_test_pred_prob` are probability vectors, we need to use the argmax function to convert them into labels (i.e. numbers 0 through 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfs1E5v4h-Xs",
        "outputId": "555e9c61-8723-48e4-802c-548c4b1ec814"
      },
      "outputs": [],
      "source": [
        "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
        "y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sqkm6dXFhEHu",
        "outputId": "da7c673c-7b0e-410a-8785-a315ac25bcfe"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "fig, axs = plt.subplots(10, 10, figsize=(20,25))\n",
        "for row in range(10):\n",
        "  for col in range(10):\n",
        "    random_index = np.random.choice(np.where(y_test_pred == row)[0])\n",
        "    axs[row][col].grid('off')\n",
        "    axs[row][col].axis('off')\n",
        "    axs[row][col].imshow(x_test[random_index].reshape(28,28), cmap='gray')\n",
        "    ax_name = 'True: {}\\nPredict: {}'.format(y_test[random_index], y_test_pred[random_index])\n",
        "    axs[row][col].set_title(ax_name)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asyQqQgtwKsa"
      },
      "source": [
        "### Save & Load sklearn model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR4Kjz1XwTzl"
      },
      "source": [
        "We use `pickle` library to save models of `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOiq35RwwNet"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/scaler.pkl\", \"wb\") as f:\n",
        "  pickle.dump(scaler, f)\n",
        "\n",
        "with open(\"/content/pca.pkl\", \"wb\") as f:\n",
        "  pickle.dump(pca, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lomk34mxBGm"
      },
      "source": [
        "After running the above code, we see in the Folder of Colab appear 2 files: `scaler.pkl` and `pca.pkl` representing 2 models StandardScaler and PCA.\n",
        "\n",
        "We will delete 2 variables `scaler` and `pca` and then use `pickle` to reload 2 saved models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsBGkUs-Mk7F"
      },
      "outputs": [],
      "source": [
        "del scaler\n",
        "del pca\n",
        "\n",
        "print(scaler, pca) # Test whether delete successfully or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kt8RbqMxaG3",
        "outputId": "63b47e50-345f-487e-c717-a00696436f30"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/scaler.pkl\", \"rb\") as f:\n",
        "  scaler = pickle.load(f)\n",
        "\n",
        "with open(\"/content/pca.pkl\", \"rb\") as f:\n",
        "  pca = pickle.load(f)\n",
        "\n",
        "print(scaler)\n",
        "print(pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YckOeryTxooY"
      },
      "source": [
        "### Save & Load Tensorflow model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzGWZw2jtZ-q"
      },
      "source": [
        "Run the cell below, we will see that in the Folder of Colab there is 1 folder named `mnist_model`. This folder contains all the things related to the model we just trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL2HL3e3rgsA",
        "outputId": "3ac3c2db-98a1-476c-e1f8-a4fbd2bae02e"
      },
      "outputs": [],
      "source": [
        "model.save('/content/mnist_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6tqepgKtoKS"
      },
      "source": [
        "Try loading the saved model, first we will delete the variable `model` first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCYHzM8wttac"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "print(model) # Test whether delete successfully or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FNaMRLCtwMe"
      },
      "source": [
        "Load model and perform evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMkxWg9rt0Zm",
        "outputId": "acd7dded-9ad2-45e6-ca7a-98bb71583225"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/mnist_model')\n",
        "model.evaluate(x_test_pca, y_test_encode)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
